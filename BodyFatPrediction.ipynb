{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srihitanuthalapati/BodyFatPrediction/blob/main/BodyFatPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJkTYxQ_Ww9t"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "mFk6xgPsPos3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "f3e72c25-a715-496a-e018-c806456ac427"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a4284741-cec1-4706-a6bc-ffebdce926e7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a4284741-cec1-4706-a6bc-ffebdce926e7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"srihitanuthalapati\",\"key\":\"fa29b797588fedd12e66720af19b668d\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r ~/.kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!mv ./kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download fedesoriano/body-fat-prediction-dataset"
      ],
      "metadata": {
        "id": "_xmXj5c5P8de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab2614c1-bb61-4fe5-c867-0335c82e4493"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/root/.kaggle': No such file or directory\n",
            "Downloading body-fat-prediction-dataset.zip to /content\n",
            "  0% 0.00/7.43k [00:00<?, ?B/s]\n",
            "100% 7.43k/7.43k [00:00<00:00, 13.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip body-fat-prediction-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fF3Fkf5PNmsU",
        "outputId": "29a9e91d-2d75-4b3b-ec4a-cc9dcf8bc66e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  body-fat-prediction-dataset.zip\n",
            "  inflating: bodyfat.csv             \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('bodyfat.csv')"
      ],
      "metadata": {
        "id": "9QYtZ7ADNFsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(torch.__version__)\n",
        "print(f\"using device: {device}\")"
      ],
      "metadata": {
        "id": "lLzCo3F-Sv2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "035d9a88-368c-4041-eb1f-83c95d323d1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu121\n",
            "using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for col in data.columns:\n",
        "  data[col] = data[col].astype('float32')\n",
        "  if col != \"Forearm\" and col != \"Density\":\n",
        "    data[col] = data[col].div(10)\n",
        "data"
      ],
      "metadata": {
        "id": "LJ9UXHa4S3w9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "36e0ae94-9757-4be2-ab7d-c8a6b59698d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Density  BodyFat  Age     Weight  Height  Neck      Chest  Abdomen  \\\n",
              "0     1.0708     1.23  2.3  15.425000   6.775  3.62   9.309999     8.52   \n",
              "1     1.0853     0.61  2.2  17.325001   7.225  3.85   9.360000     8.30   \n",
              "2     1.0414     2.53  2.2  15.400000   6.625  3.40   9.580000     8.79   \n",
              "3     1.0751     1.04  2.6  18.475000   7.225  3.74  10.180000     8.64   \n",
              "4     1.0340     2.87  2.4  18.424999   7.125  3.44   9.730000    10.00   \n",
              "..       ...      ...  ...        ...     ...   ...        ...      ...   \n",
              "247   1.0736     1.10  7.0  13.425000   6.700  3.49   8.920000     8.36   \n",
              "248   1.0236     3.36  7.2  20.100000   6.975  4.09  10.850000    10.50   \n",
              "249   1.0328     2.93  7.2  18.674999   6.600  3.89  11.110000    11.15   \n",
              "250   1.0399     2.60  7.2  19.075001   7.050  3.89  10.830000    10.13   \n",
              "251   1.0271     3.19  7.4  20.750000   7.000  4.08  11.240000    10.85   \n",
              "\n",
              "           Hip  Thigh  Knee  Ankle  Biceps    Forearm  Wrist  \n",
              "0     9.450000   5.90  3.73   2.19    3.20  27.400000   1.71  \n",
              "1     9.870000   5.87  3.73   2.34    3.05  28.900000   1.82  \n",
              "2     9.920000   5.96  3.89   2.40    2.88  25.200001   1.66  \n",
              "3    10.120000   6.01  3.73   2.28    3.24  29.400000   1.82  \n",
              "4    10.190001   6.32  4.22   2.40    3.22  27.700001   1.77  \n",
              "..         ...    ...   ...    ...     ...        ...    ...  \n",
              "247   8.880000   4.96  3.48   2.15    2.56  25.700001   1.85  \n",
              "248  10.450000   5.96  4.08   2.32    3.52  28.600000   2.01  \n",
              "249  10.170000   6.03  3.73   2.15    3.13  27.200001   1.80  \n",
              "250   9.780001   5.60  4.16   2.27    3.05  29.400000   1.98  \n",
              "251  10.710000   5.93  4.22   2.46    3.37  30.000000   2.09  \n",
              "\n",
              "[252 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-113eb697-bcd3-4be8-a6db-39ecd4ac97b8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Density</th>\n",
              "      <th>BodyFat</th>\n",
              "      <th>Age</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Height</th>\n",
              "      <th>Neck</th>\n",
              "      <th>Chest</th>\n",
              "      <th>Abdomen</th>\n",
              "      <th>Hip</th>\n",
              "      <th>Thigh</th>\n",
              "      <th>Knee</th>\n",
              "      <th>Ankle</th>\n",
              "      <th>Biceps</th>\n",
              "      <th>Forearm</th>\n",
              "      <th>Wrist</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0708</td>\n",
              "      <td>1.23</td>\n",
              "      <td>2.3</td>\n",
              "      <td>15.425000</td>\n",
              "      <td>6.775</td>\n",
              "      <td>3.62</td>\n",
              "      <td>9.309999</td>\n",
              "      <td>8.52</td>\n",
              "      <td>9.450000</td>\n",
              "      <td>5.90</td>\n",
              "      <td>3.73</td>\n",
              "      <td>2.19</td>\n",
              "      <td>3.20</td>\n",
              "      <td>27.400000</td>\n",
              "      <td>1.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0853</td>\n",
              "      <td>0.61</td>\n",
              "      <td>2.2</td>\n",
              "      <td>17.325001</td>\n",
              "      <td>7.225</td>\n",
              "      <td>3.85</td>\n",
              "      <td>9.360000</td>\n",
              "      <td>8.30</td>\n",
              "      <td>9.870000</td>\n",
              "      <td>5.87</td>\n",
              "      <td>3.73</td>\n",
              "      <td>2.34</td>\n",
              "      <td>3.05</td>\n",
              "      <td>28.900000</td>\n",
              "      <td>1.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0414</td>\n",
              "      <td>2.53</td>\n",
              "      <td>2.2</td>\n",
              "      <td>15.400000</td>\n",
              "      <td>6.625</td>\n",
              "      <td>3.40</td>\n",
              "      <td>9.580000</td>\n",
              "      <td>8.79</td>\n",
              "      <td>9.920000</td>\n",
              "      <td>5.96</td>\n",
              "      <td>3.89</td>\n",
              "      <td>2.40</td>\n",
              "      <td>2.88</td>\n",
              "      <td>25.200001</td>\n",
              "      <td>1.66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0751</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.6</td>\n",
              "      <td>18.475000</td>\n",
              "      <td>7.225</td>\n",
              "      <td>3.74</td>\n",
              "      <td>10.180000</td>\n",
              "      <td>8.64</td>\n",
              "      <td>10.120000</td>\n",
              "      <td>6.01</td>\n",
              "      <td>3.73</td>\n",
              "      <td>2.28</td>\n",
              "      <td>3.24</td>\n",
              "      <td>29.400000</td>\n",
              "      <td>1.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0340</td>\n",
              "      <td>2.87</td>\n",
              "      <td>2.4</td>\n",
              "      <td>18.424999</td>\n",
              "      <td>7.125</td>\n",
              "      <td>3.44</td>\n",
              "      <td>9.730000</td>\n",
              "      <td>10.00</td>\n",
              "      <td>10.190001</td>\n",
              "      <td>6.32</td>\n",
              "      <td>4.22</td>\n",
              "      <td>2.40</td>\n",
              "      <td>3.22</td>\n",
              "      <td>27.700001</td>\n",
              "      <td>1.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247</th>\n",
              "      <td>1.0736</td>\n",
              "      <td>1.10</td>\n",
              "      <td>7.0</td>\n",
              "      <td>13.425000</td>\n",
              "      <td>6.700</td>\n",
              "      <td>3.49</td>\n",
              "      <td>8.920000</td>\n",
              "      <td>8.36</td>\n",
              "      <td>8.880000</td>\n",
              "      <td>4.96</td>\n",
              "      <td>3.48</td>\n",
              "      <td>2.15</td>\n",
              "      <td>2.56</td>\n",
              "      <td>25.700001</td>\n",
              "      <td>1.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>1.0236</td>\n",
              "      <td>3.36</td>\n",
              "      <td>7.2</td>\n",
              "      <td>20.100000</td>\n",
              "      <td>6.975</td>\n",
              "      <td>4.09</td>\n",
              "      <td>10.850000</td>\n",
              "      <td>10.50</td>\n",
              "      <td>10.450000</td>\n",
              "      <td>5.96</td>\n",
              "      <td>4.08</td>\n",
              "      <td>2.32</td>\n",
              "      <td>3.52</td>\n",
              "      <td>28.600000</td>\n",
              "      <td>2.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>1.0328</td>\n",
              "      <td>2.93</td>\n",
              "      <td>7.2</td>\n",
              "      <td>18.674999</td>\n",
              "      <td>6.600</td>\n",
              "      <td>3.89</td>\n",
              "      <td>11.110000</td>\n",
              "      <td>11.15</td>\n",
              "      <td>10.170000</td>\n",
              "      <td>6.03</td>\n",
              "      <td>3.73</td>\n",
              "      <td>2.15</td>\n",
              "      <td>3.13</td>\n",
              "      <td>27.200001</td>\n",
              "      <td>1.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>1.0399</td>\n",
              "      <td>2.60</td>\n",
              "      <td>7.2</td>\n",
              "      <td>19.075001</td>\n",
              "      <td>7.050</td>\n",
              "      <td>3.89</td>\n",
              "      <td>10.830000</td>\n",
              "      <td>10.13</td>\n",
              "      <td>9.780001</td>\n",
              "      <td>5.60</td>\n",
              "      <td>4.16</td>\n",
              "      <td>2.27</td>\n",
              "      <td>3.05</td>\n",
              "      <td>29.400000</td>\n",
              "      <td>1.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>1.0271</td>\n",
              "      <td>3.19</td>\n",
              "      <td>7.4</td>\n",
              "      <td>20.750000</td>\n",
              "      <td>7.000</td>\n",
              "      <td>4.08</td>\n",
              "      <td>11.240000</td>\n",
              "      <td>10.85</td>\n",
              "      <td>10.710000</td>\n",
              "      <td>5.93</td>\n",
              "      <td>4.22</td>\n",
              "      <td>2.46</td>\n",
              "      <td>3.37</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>2.09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>252 rows Ã— 15 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-113eb697-bcd3-4be8-a6db-39ecd4ac97b8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-113eb697-bcd3-4be8-a6db-39ecd4ac97b8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-113eb697-bcd3-4be8-a6db-39ecd4ac97b8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4f17afab-2959-4d7c-bf5c-3daca294e5ca\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4f17afab-2959-4d7c-bf5c-3daca294e5ca')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4f17afab-2959-4d7c-bf5c-3daca294e5ca button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_467c08bd-0689-412f-82d5-37eb53f2757e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_467c08bd-0689-412f-82d5-37eb53f2757e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 252,\n  \"fields\": [\n    {\n      \"column\": \"Density\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"samples\": [\n          1.0547000169754028,\n          1.0235999822616577,\n          1.0872999429702759\n        ],\n        \"num_unique_values\": 218,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BodyFat\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"samples\": [\n          1.9100000858306885,\n          1.3600000143051147,\n          1.2100000381469727\n        ],\n        \"num_unique_values\": 176,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"samples\": [\n          5.199999809265137,\n          7.199999809265137,\n          6.0\n        ],\n        \"num_unique_values\": 51,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weight\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"samples\": [\n          22.674999237060547,\n          19.225000381469727,\n          19.575000762939453\n        ],\n        \"num_unique_values\": 197,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Height\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"samples\": [\n          6.849999904632568,\n          7.775000095367432,\n          7.324999809265137\n        ],\n        \"num_unique_values\": 48,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Neck\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"samples\": [\n          3.9900002479553223,\n          3.879999876022339,\n          3.5900001525878906\n        ],\n        \"num_unique_values\": 90,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Chest\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"samples\": [\n          9.280000686645508,\n          9.199999809265137,\n          10.390000343322754\n        ],\n        \"num_unique_values\": 174,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Abdomen\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"samples\": [\n          9.59000015258789,\n          7.949999809265137,\n          10.309999465942383\n        ],\n        \"num_unique_values\": 185,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hip\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"samples\": [\n          10.019999504089355,\n          8.760000228881836,\n          9.319999694824219\n        ],\n        \"num_unique_values\": 152,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Thigh\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"samples\": [\n          5.070000171661377,\n          5.480000019073486,\n          8.730000495910645\n        ],\n        \"num_unique_values\": 139,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Knee\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"samples\": [\n          3.7599997520446777,\n          3.450000047683716,\n          3.950000047683716\n        ],\n        \"num_unique_values\": 90,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ankle\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"samples\": [\n          2.190000057220459,\n          2.2899999618530273,\n          2.4800000190734863\n        ],\n        \"num_unique_values\": 61,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Biceps\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"samples\": [\n          4.5,\n          3.059999942779541,\n          3.2900002002716064\n        ],\n        \"num_unique_values\": 104,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Forearm\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"samples\": [\n          27.700000762939453,\n          25.5,\n          30.200000762939453\n        ],\n        \"num_unique_values\": 77,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Wrist\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"samples\": [\n          1.75,\n          1.7400000095367432,\n          1.6100000143051147\n        ],\n        \"num_unique_values\": 44,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PredictionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PredictionModel, self).__init__()\n",
        "        input_size = 14\n",
        "        hidden_size = 10\n",
        "        output_size = 1\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "7O6cI1D6Vte1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BodyFatDataset(Dataset):\n",
        "    def __init__(self, data, transform=None):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        a = self.data.iloc[index, 1:].values\n",
        "        b = self.data.iloc[index, 1]\n",
        "        return a, b"
      ],
      "metadata": {
        "id": "NnpYcPgBV14U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = PredictionModel()\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.L1Loss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "qy9qb5PwWxOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvEzuTc1UvYB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e52e799d-b7c8-4c83-8d38-8e1a3c176b94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([50])) that is different to the input size (torch.Size([50, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/300], Loss: 1.9284\n",
            "Epoch [1/300], Loss: 2.0161\n",
            "Epoch [1/300], Loss: 2.0668\n",
            "Epoch [1/300], Loss: 2.2210\n",
            "Epoch [1/300], Loss: 2.0928\n",
            "Epoch [1/300], Loss: 1.1101\n",
            "Epoch [2/300], Loss: 2.0461\n",
            "Epoch [2/300], Loss: 2.0435\n",
            "Epoch [2/300], Loss: 2.0228\n",
            "Epoch [2/300], Loss: 1.9102\n",
            "Epoch [2/300], Loss: 1.9495\n",
            "Epoch [2/300], Loss: 0.8633\n",
            "Epoch [3/300], Loss: 1.8273\n",
            "Epoch [3/300], Loss: 1.9248\n",
            "Epoch [3/300], Loss: 1.9465\n",
            "Epoch [3/300], Loss: 1.9775\n",
            "Epoch [3/300], Loss: 1.9191\n",
            "Epoch [3/300], Loss: 0.9649\n",
            "Epoch [4/300], Loss: 1.9622\n",
            "Epoch [4/300], Loss: 1.7985\n",
            "Epoch [4/300], Loss: 1.6102\n",
            "Epoch [4/300], Loss: 1.8801\n",
            "Epoch [4/300], Loss: 1.9678\n",
            "Epoch [4/300], Loss: 0.9133\n",
            "Epoch [5/300], Loss: 1.8225\n",
            "Epoch [5/300], Loss: 1.7872\n",
            "Epoch [5/300], Loss: 1.7011\n",
            "Epoch [5/300], Loss: 1.7389\n",
            "Epoch [5/300], Loss: 1.7414\n",
            "Epoch [5/300], Loss: 2.3512\n",
            "Epoch [6/300], Loss: 1.7136\n",
            "Epoch [6/300], Loss: 1.5351\n",
            "Epoch [6/300], Loss: 1.6439\n",
            "Epoch [6/300], Loss: 1.7178\n",
            "Epoch [6/300], Loss: 1.8331\n",
            "Epoch [6/300], Loss: 1.8582\n",
            "Epoch [7/300], Loss: 1.6141\n",
            "Epoch [7/300], Loss: 1.6462\n",
            "Epoch [7/300], Loss: 1.5598\n",
            "Epoch [7/300], Loss: 1.6951\n",
            "Epoch [7/300], Loss: 1.5909\n",
            "Epoch [7/300], Loss: 0.8882\n",
            "Epoch [8/300], Loss: 1.5982\n",
            "Epoch [8/300], Loss: 1.5547\n",
            "Epoch [8/300], Loss: 1.4467\n",
            "Epoch [8/300], Loss: 1.5036\n",
            "Epoch [8/300], Loss: 1.6073\n",
            "Epoch [8/300], Loss: 1.7691\n",
            "Epoch [9/300], Loss: 1.5691\n",
            "Epoch [9/300], Loss: 1.3774\n",
            "Epoch [9/300], Loss: 1.4699\n",
            "Epoch [9/300], Loss: 1.4851\n",
            "Epoch [9/300], Loss: 1.4687\n",
            "Epoch [9/300], Loss: 1.4570\n",
            "Epoch [10/300], Loss: 1.2918\n",
            "Epoch [10/300], Loss: 1.4701\n",
            "Epoch [10/300], Loss: 1.3729\n",
            "Epoch [10/300], Loss: 1.4220\n",
            "Epoch [10/300], Loss: 1.4715\n",
            "Epoch [10/300], Loss: 1.3337\n",
            "Epoch [11/300], Loss: 1.3530\n",
            "Epoch [11/300], Loss: 1.3505\n",
            "Epoch [11/300], Loss: 1.4362\n",
            "Epoch [11/300], Loss: 1.3284\n",
            "Epoch [11/300], Loss: 1.2444\n",
            "Epoch [11/300], Loss: 1.1466\n",
            "Epoch [12/300], Loss: 1.3182\n",
            "Epoch [12/300], Loss: 1.3710\n",
            "Epoch [12/300], Loss: 1.3059\n",
            "Epoch [12/300], Loss: 1.2000\n",
            "Epoch [12/300], Loss: 1.2078\n",
            "Epoch [12/300], Loss: 0.9084\n",
            "Epoch [13/300], Loss: 1.2524\n",
            "Epoch [13/300], Loss: 1.2492\n",
            "Epoch [13/300], Loss: 1.1276\n",
            "Epoch [13/300], Loss: 1.3011\n",
            "Epoch [13/300], Loss: 1.1660\n",
            "Epoch [13/300], Loss: 0.6900\n",
            "Epoch [14/300], Loss: 1.0669\n",
            "Epoch [14/300], Loss: 1.1948\n",
            "Epoch [14/300], Loss: 1.1480\n",
            "Epoch [14/300], Loss: 1.3046\n",
            "Epoch [14/300], Loss: 1.0832\n",
            "Epoch [14/300], Loss: 1.6936\n",
            "Epoch [15/300], Loss: 1.3544\n",
            "Epoch [15/300], Loss: 1.0921\n",
            "Epoch [15/300], Loss: 1.0621\n",
            "Epoch [15/300], Loss: 0.9692\n",
            "Epoch [15/300], Loss: 1.0872\n",
            "Epoch [15/300], Loss: 1.6003\n",
            "Epoch [16/300], Loss: 1.0974\n",
            "Epoch [16/300], Loss: 1.0339\n",
            "Epoch [16/300], Loss: 1.1671\n",
            "Epoch [16/300], Loss: 1.0462\n",
            "Epoch [16/300], Loss: 0.9952\n",
            "Epoch [16/300], Loss: 0.7200\n",
            "Epoch [17/300], Loss: 1.0004\n",
            "Epoch [17/300], Loss: 1.0989\n",
            "Epoch [17/300], Loss: 0.9762\n",
            "Epoch [17/300], Loss: 0.9720\n",
            "Epoch [17/300], Loss: 1.1056\n",
            "Epoch [17/300], Loss: 0.5119\n",
            "Epoch [18/300], Loss: 0.9945\n",
            "Epoch [18/300], Loss: 1.0294\n",
            "Epoch [18/300], Loss: 0.9732\n",
            "Epoch [18/300], Loss: 0.9589\n",
            "Epoch [18/300], Loss: 0.9796\n",
            "Epoch [18/300], Loss: 2.0362\n",
            "Epoch [19/300], Loss: 1.0427\n",
            "Epoch [19/300], Loss: 1.0168\n",
            "Epoch [19/300], Loss: 0.9953\n",
            "Epoch [19/300], Loss: 0.9519\n",
            "Epoch [19/300], Loss: 0.8052\n",
            "Epoch [19/300], Loss: 0.8279\n",
            "Epoch [20/300], Loss: 0.9155\n",
            "Epoch [20/300], Loss: 1.0517\n",
            "Epoch [20/300], Loss: 0.8064\n",
            "Epoch [20/300], Loss: 0.8693\n",
            "Epoch [20/300], Loss: 0.9388\n",
            "Epoch [20/300], Loss: 2.2941\n",
            "Epoch [21/300], Loss: 0.8662\n",
            "Epoch [21/300], Loss: 0.9971\n",
            "Epoch [21/300], Loss: 0.8789\n",
            "Epoch [21/300], Loss: 0.9039\n",
            "Epoch [21/300], Loss: 0.8619\n",
            "Epoch [21/300], Loss: 1.2736\n",
            "Epoch [22/300], Loss: 0.7330\n",
            "Epoch [22/300], Loss: 0.9460\n",
            "Epoch [22/300], Loss: 0.9534\n",
            "Epoch [22/300], Loss: 0.8232\n",
            "Epoch [22/300], Loss: 0.9487\n",
            "Epoch [22/300], Loss: 0.3849\n",
            "Epoch [23/300], Loss: 0.8193\n",
            "Epoch [23/300], Loss: 0.8577\n",
            "Epoch [23/300], Loss: 0.8442\n",
            "Epoch [23/300], Loss: 0.8967\n",
            "Epoch [23/300], Loss: 0.8874\n",
            "Epoch [23/300], Loss: 0.2754\n",
            "Epoch [24/300], Loss: 0.9182\n",
            "Epoch [24/300], Loss: 0.8202\n",
            "Epoch [24/300], Loss: 0.8171\n",
            "Epoch [24/300], Loss: 0.8459\n",
            "Epoch [24/300], Loss: 0.8004\n",
            "Epoch [24/300], Loss: 0.1652\n",
            "Epoch [25/300], Loss: 0.7943\n",
            "Epoch [25/300], Loss: 0.7700\n",
            "Epoch [25/300], Loss: 0.8909\n",
            "Epoch [25/300], Loss: 0.8883\n",
            "Epoch [25/300], Loss: 0.7608\n",
            "Epoch [25/300], Loss: 0.7002\n",
            "Epoch [26/300], Loss: 0.8113\n",
            "Epoch [26/300], Loss: 0.8748\n",
            "Epoch [26/300], Loss: 0.8871\n",
            "Epoch [26/300], Loss: 0.7440\n",
            "Epoch [26/300], Loss: 0.7189\n",
            "Epoch [26/300], Loss: 1.0201\n",
            "Epoch [27/300], Loss: 0.7554\n",
            "Epoch [27/300], Loss: 0.6987\n",
            "Epoch [27/300], Loss: 0.8775\n",
            "Epoch [27/300], Loss: 0.7780\n",
            "Epoch [27/300], Loss: 0.8814\n",
            "Epoch [27/300], Loss: 0.8600\n",
            "Epoch [28/300], Loss: 0.7428\n",
            "Epoch [28/300], Loss: 0.7732\n",
            "Epoch [28/300], Loss: 0.7821\n",
            "Epoch [28/300], Loss: 0.8054\n",
            "Epoch [28/300], Loss: 0.8139\n",
            "Epoch [28/300], Loss: 0.7590\n",
            "Epoch [29/300], Loss: 0.8075\n",
            "Epoch [29/300], Loss: 0.8724\n",
            "Epoch [29/300], Loss: 0.6303\n",
            "Epoch [29/300], Loss: 0.7604\n",
            "Epoch [29/300], Loss: 0.8436\n",
            "Epoch [29/300], Loss: 0.1787\n",
            "Epoch [30/300], Loss: 0.7331\n",
            "Epoch [30/300], Loss: 0.7790\n",
            "Epoch [30/300], Loss: 0.7490\n",
            "Epoch [30/300], Loss: 0.7669\n",
            "Epoch [30/300], Loss: 0.7652\n",
            "Epoch [30/300], Loss: 1.9853\n",
            "Epoch [31/300], Loss: 0.8653\n",
            "Epoch [31/300], Loss: 0.8214\n",
            "Epoch [31/300], Loss: 0.7217\n",
            "Epoch [31/300], Loss: 0.7169\n",
            "Epoch [31/300], Loss: 0.7033\n",
            "Epoch [31/300], Loss: 0.5268\n",
            "Epoch [32/300], Loss: 0.7654\n",
            "Epoch [32/300], Loss: 0.7281\n",
            "Epoch [32/300], Loss: 0.7364\n",
            "Epoch [32/300], Loss: 0.7742\n",
            "Epoch [32/300], Loss: 0.7793\n",
            "Epoch [32/300], Loss: 0.8868\n",
            "Epoch [33/300], Loss: 0.7282\n",
            "Epoch [33/300], Loss: 0.7532\n",
            "Epoch [33/300], Loss: 0.7260\n",
            "Epoch [33/300], Loss: 0.7964\n",
            "Epoch [33/300], Loss: 0.7805\n",
            "Epoch [33/300], Loss: 0.6266\n",
            "Epoch [34/300], Loss: 0.7653\n",
            "Epoch [34/300], Loss: 0.8086\n",
            "Epoch [34/300], Loss: 0.6308\n",
            "Epoch [34/300], Loss: 0.7799\n",
            "Epoch [34/300], Loss: 0.7705\n",
            "Epoch [34/300], Loss: 0.7700\n",
            "Epoch [35/300], Loss: 0.7053\n",
            "Epoch [35/300], Loss: 0.8060\n",
            "Epoch [35/300], Loss: 0.6936\n",
            "Epoch [35/300], Loss: 0.7562\n",
            "Epoch [35/300], Loss: 0.7913\n",
            "Epoch [35/300], Loss: 0.5750\n",
            "Epoch [36/300], Loss: 0.7690\n",
            "Epoch [36/300], Loss: 0.7792\n",
            "Epoch [36/300], Loss: 0.7092\n",
            "Epoch [36/300], Loss: 0.7730\n",
            "Epoch [36/300], Loss: 0.6882\n",
            "Epoch [36/300], Loss: 0.7750\n",
            "Epoch [37/300], Loss: 0.6928\n",
            "Epoch [37/300], Loss: 0.7017\n",
            "Epoch [37/300], Loss: 0.8458\n",
            "Epoch [37/300], Loss: 0.7125\n",
            "Epoch [37/300], Loss: 0.7730\n",
            "Epoch [37/300], Loss: 0.7490\n",
            "Epoch [38/300], Loss: 0.7090\n",
            "Epoch [38/300], Loss: 0.7664\n",
            "Epoch [38/300], Loss: 0.6949\n",
            "Epoch [38/300], Loss: 0.8259\n",
            "Epoch [38/300], Loss: 0.7165\n",
            "Epoch [38/300], Loss: 0.5125\n",
            "Epoch [39/300], Loss: 0.7287\n",
            "Epoch [39/300], Loss: 0.6289\n",
            "Epoch [39/300], Loss: 0.8455\n",
            "Epoch [39/300], Loss: 0.7525\n",
            "Epoch [39/300], Loss: 0.7357\n",
            "Epoch [39/300], Loss: 0.6152\n",
            "Epoch [40/300], Loss: 0.6691\n",
            "Epoch [40/300], Loss: 0.7689\n",
            "Epoch [40/300], Loss: 0.7849\n",
            "Epoch [40/300], Loss: 0.7144\n",
            "Epoch [40/300], Loss: 0.7646\n",
            "Epoch [40/300], Loss: 0.2100\n",
            "Epoch [41/300], Loss: 0.7000\n",
            "Epoch [41/300], Loss: 0.7689\n",
            "Epoch [41/300], Loss: 0.7371\n",
            "Epoch [41/300], Loss: 0.7628\n",
            "Epoch [41/300], Loss: 0.6969\n",
            "Epoch [41/300], Loss: 1.2050\n",
            "Epoch [42/300], Loss: 0.7926\n",
            "Epoch [42/300], Loss: 0.6804\n",
            "Epoch [42/300], Loss: 0.6965\n",
            "Epoch [42/300], Loss: 0.6838\n",
            "Epoch [42/300], Loss: 0.7941\n",
            "Epoch [42/300], Loss: 1.0115\n",
            "Epoch [43/300], Loss: 0.7242\n",
            "Epoch [43/300], Loss: 0.7367\n",
            "Epoch [43/300], Loss: 0.7261\n",
            "Epoch [43/300], Loss: 0.8222\n",
            "Epoch [43/300], Loss: 0.6940\n",
            "Epoch [43/300], Loss: 0.2635\n",
            "Epoch [44/300], Loss: 0.7604\n",
            "Epoch [44/300], Loss: 0.7498\n",
            "Epoch [44/300], Loss: 0.7290\n",
            "Epoch [44/300], Loss: 0.7194\n",
            "Epoch [44/300], Loss: 0.7030\n",
            "Epoch [44/300], Loss: 1.5100\n",
            "Epoch [45/300], Loss: 0.6887\n",
            "Epoch [45/300], Loss: 0.7527\n",
            "Epoch [45/300], Loss: 0.7386\n",
            "Epoch [45/300], Loss: 0.7286\n",
            "Epoch [45/300], Loss: 0.7803\n",
            "Epoch [45/300], Loss: 0.7500\n",
            "Epoch [46/300], Loss: 0.7956\n",
            "Epoch [46/300], Loss: 0.6479\n",
            "Epoch [46/300], Loss: 0.7497\n",
            "Epoch [46/300], Loss: 0.7449\n",
            "Epoch [46/300], Loss: 0.7193\n",
            "Epoch [46/300], Loss: 0.9700\n",
            "Epoch [47/300], Loss: 0.5798\n",
            "Epoch [47/300], Loss: 0.8583\n",
            "Epoch [47/300], Loss: 0.6142\n",
            "Epoch [47/300], Loss: 0.7605\n",
            "Epoch [47/300], Loss: 0.8395\n",
            "Epoch [47/300], Loss: 1.2150\n",
            "Epoch [48/300], Loss: 0.8670\n",
            "Epoch [48/300], Loss: 0.6339\n",
            "Epoch [48/300], Loss: 0.7821\n",
            "Epoch [48/300], Loss: 0.6516\n",
            "Epoch [48/300], Loss: 0.7655\n",
            "Epoch [48/300], Loss: 0.3158\n",
            "Epoch [49/300], Loss: 0.7257\n",
            "Epoch [49/300], Loss: 0.6651\n",
            "Epoch [49/300], Loss: 0.7073\n",
            "Epoch [49/300], Loss: 0.8033\n",
            "Epoch [49/300], Loss: 0.7707\n",
            "Epoch [49/300], Loss: 0.6816\n",
            "Epoch [50/300], Loss: 0.7189\n",
            "Epoch [50/300], Loss: 0.7765\n",
            "Epoch [50/300], Loss: 0.7624\n",
            "Epoch [50/300], Loss: 0.6906\n",
            "Epoch [50/300], Loss: 0.6837\n",
            "Epoch [50/300], Loss: 0.8585\n",
            "Epoch [51/300], Loss: 0.7274\n",
            "Epoch [51/300], Loss: 0.7221\n",
            "Epoch [51/300], Loss: 0.7313\n",
            "Epoch [51/300], Loss: 0.6673\n",
            "Epoch [51/300], Loss: 0.7694\n",
            "Epoch [51/300], Loss: 1.0396\n",
            "Epoch [52/300], Loss: 0.6769\n",
            "Epoch [52/300], Loss: 0.7316\n",
            "Epoch [52/300], Loss: 0.7049\n",
            "Epoch [52/300], Loss: 0.7850\n",
            "Epoch [52/300], Loss: 0.7945\n",
            "Epoch [52/300], Loss: 0.0875\n",
            "Epoch [53/300], Loss: 0.7668\n",
            "Epoch [53/300], Loss: 0.7666\n",
            "Epoch [53/300], Loss: 0.6385\n",
            "Epoch [53/300], Loss: 0.7746\n",
            "Epoch [53/300], Loss: 0.6911\n",
            "Epoch [53/300], Loss: 1.2300\n",
            "Epoch [54/300], Loss: 0.7438\n",
            "Epoch [54/300], Loss: 0.7188\n",
            "Epoch [54/300], Loss: 0.7117\n",
            "Epoch [54/300], Loss: 0.7035\n",
            "Epoch [54/300], Loss: 0.7874\n",
            "Epoch [54/300], Loss: 0.1405\n",
            "Epoch [55/300], Loss: 0.7294\n",
            "Epoch [55/300], Loss: 0.7634\n",
            "Epoch [55/300], Loss: 0.7395\n",
            "Epoch [55/300], Loss: 0.6943\n",
            "Epoch [55/300], Loss: 0.7455\n",
            "Epoch [55/300], Loss: 0.2856\n",
            "Epoch [56/300], Loss: 0.7211\n",
            "Epoch [56/300], Loss: 0.8139\n",
            "Epoch [56/300], Loss: 0.7023\n",
            "Epoch [56/300], Loss: 0.6414\n",
            "Epoch [56/300], Loss: 0.7741\n",
            "Epoch [56/300], Loss: 1.1547\n",
            "Epoch [57/300], Loss: 0.8539\n",
            "Epoch [57/300], Loss: 0.6076\n",
            "Epoch [57/300], Loss: 0.7245\n",
            "Epoch [57/300], Loss: 0.7403\n",
            "Epoch [57/300], Loss: 0.7376\n",
            "Epoch [57/300], Loss: 0.7870\n",
            "Epoch [58/300], Loss: 0.6778\n",
            "Epoch [58/300], Loss: 0.7395\n",
            "Epoch [58/300], Loss: 0.6772\n",
            "Epoch [58/300], Loss: 0.7722\n",
            "Epoch [58/300], Loss: 0.7922\n",
            "Epoch [58/300], Loss: 0.8400\n",
            "Epoch [59/300], Loss: 0.8044\n",
            "Epoch [59/300], Loss: 0.7218\n",
            "Epoch [59/300], Loss: 0.7090\n",
            "Epoch [59/300], Loss: 0.7354\n",
            "Epoch [59/300], Loss: 0.6939\n",
            "Epoch [59/300], Loss: 0.6720\n",
            "Epoch [60/300], Loss: 0.7242\n",
            "Epoch [60/300], Loss: 0.6630\n",
            "Epoch [60/300], Loss: 0.8286\n",
            "Epoch [60/300], Loss: 0.6879\n",
            "Epoch [60/300], Loss: 0.7638\n",
            "Epoch [60/300], Loss: 0.1873\n",
            "Epoch [61/300], Loss: 0.7340\n",
            "Epoch [61/300], Loss: 0.7183\n",
            "Epoch [61/300], Loss: 0.8079\n",
            "Epoch [61/300], Loss: 0.7120\n",
            "Epoch [61/300], Loss: 0.7207\n",
            "Epoch [61/300], Loss: 0.2502\n",
            "Epoch [62/300], Loss: 0.8203\n",
            "Epoch [62/300], Loss: 0.7480\n",
            "Epoch [62/300], Loss: 0.7589\n",
            "Epoch [62/300], Loss: 0.5947\n",
            "Epoch [62/300], Loss: 0.7422\n",
            "Epoch [62/300], Loss: 0.5050\n",
            "Epoch [63/300], Loss: 0.7236\n",
            "Epoch [63/300], Loss: 0.6882\n",
            "Epoch [63/300], Loss: 0.8371\n",
            "Epoch [63/300], Loss: 0.7089\n",
            "Epoch [63/300], Loss: 0.6780\n",
            "Epoch [63/300], Loss: 1.3242\n",
            "Epoch [64/300], Loss: 0.7031\n",
            "Epoch [64/300], Loss: 0.8353\n",
            "Epoch [64/300], Loss: 0.7419\n",
            "Epoch [64/300], Loss: 0.6158\n",
            "Epoch [64/300], Loss: 0.7460\n",
            "Epoch [64/300], Loss: 0.8907\n",
            "Epoch [65/300], Loss: 0.6531\n",
            "Epoch [65/300], Loss: 0.7817\n",
            "Epoch [65/300], Loss: 0.7150\n",
            "Epoch [65/300], Loss: 0.7623\n",
            "Epoch [65/300], Loss: 0.7598\n",
            "Epoch [65/300], Loss: 0.6700\n",
            "Epoch [66/300], Loss: 0.7535\n",
            "Epoch [66/300], Loss: 0.7510\n",
            "Epoch [66/300], Loss: 0.8068\n",
            "Epoch [66/300], Loss: 0.7208\n",
            "Epoch [66/300], Loss: 0.5987\n",
            "Epoch [66/300], Loss: 1.1500\n",
            "Epoch [67/300], Loss: 0.6938\n",
            "Epoch [67/300], Loss: 0.8299\n",
            "Epoch [67/300], Loss: 0.6641\n",
            "Epoch [67/300], Loss: 0.7424\n",
            "Epoch [67/300], Loss: 0.7366\n",
            "Epoch [67/300], Loss: 0.8100\n",
            "Epoch [68/300], Loss: 0.6712\n",
            "Epoch [68/300], Loss: 0.7506\n",
            "Epoch [68/300], Loss: 0.7544\n",
            "Epoch [68/300], Loss: 0.6938\n",
            "Epoch [68/300], Loss: 0.7550\n",
            "Epoch [68/300], Loss: 0.7375\n",
            "Epoch [69/300], Loss: 0.7220\n",
            "Epoch [69/300], Loss: 0.7236\n",
            "Epoch [69/300], Loss: 0.6933\n",
            "Epoch [69/300], Loss: 0.7770\n",
            "Epoch [69/300], Loss: 0.7248\n",
            "Epoch [69/300], Loss: 1.1654\n",
            "Epoch [70/300], Loss: 0.7045\n",
            "Epoch [70/300], Loss: 0.7350\n",
            "Epoch [70/300], Loss: 0.7503\n",
            "Epoch [70/300], Loss: 0.7517\n",
            "Epoch [70/300], Loss: 0.7161\n",
            "Epoch [70/300], Loss: 0.8151\n",
            "Epoch [71/300], Loss: 0.6803\n",
            "Epoch [71/300], Loss: 0.6877\n",
            "Epoch [71/300], Loss: 0.7157\n",
            "Epoch [71/300], Loss: 0.7974\n",
            "Epoch [71/300], Loss: 0.7751\n",
            "Epoch [71/300], Loss: 0.2860\n",
            "Epoch [72/300], Loss: 0.7062\n",
            "Epoch [72/300], Loss: 0.7387\n",
            "Epoch [72/300], Loss: 0.7939\n",
            "Epoch [72/300], Loss: 0.7306\n",
            "Epoch [72/300], Loss: 0.6823\n",
            "Epoch [72/300], Loss: 0.5104\n",
            "Epoch [73/300], Loss: 0.6746\n",
            "Epoch [73/300], Loss: 0.6907\n",
            "Epoch [73/300], Loss: 0.8841\n",
            "Epoch [73/300], Loss: 0.6832\n",
            "Epoch [73/300], Loss: 0.7005\n",
            "Epoch [73/300], Loss: 0.8786\n",
            "Epoch [74/300], Loss: 0.6854\n",
            "Epoch [74/300], Loss: 0.5980\n",
            "Epoch [74/300], Loss: 0.8762\n",
            "Epoch [74/300], Loss: 0.7324\n",
            "Epoch [74/300], Loss: 0.7384\n",
            "Epoch [74/300], Loss: 0.4637\n",
            "Epoch [75/300], Loss: 0.8585\n",
            "Epoch [75/300], Loss: 0.7004\n",
            "Epoch [75/300], Loss: 0.6782\n",
            "Epoch [75/300], Loss: 0.6697\n",
            "Epoch [75/300], Loss: 0.7344\n",
            "Epoch [75/300], Loss: 0.6650\n",
            "Epoch [76/300], Loss: 0.7360\n",
            "Epoch [76/300], Loss: 0.6695\n",
            "Epoch [76/300], Loss: 0.7077\n",
            "Epoch [76/300], Loss: 0.7044\n",
            "Epoch [76/300], Loss: 0.8291\n",
            "Epoch [76/300], Loss: 0.9850\n",
            "Epoch [77/300], Loss: 0.7945\n",
            "Epoch [77/300], Loss: 0.7824\n",
            "Epoch [77/300], Loss: 0.7565\n",
            "Epoch [77/300], Loss: 0.6302\n",
            "Epoch [77/300], Loss: 0.6894\n",
            "Epoch [77/300], Loss: 0.5450\n",
            "Epoch [78/300], Loss: 0.7930\n",
            "Epoch [78/300], Loss: 0.7227\n",
            "Epoch [78/300], Loss: 0.6953\n",
            "Epoch [78/300], Loss: 0.6745\n",
            "Epoch [78/300], Loss: 0.7571\n",
            "Epoch [78/300], Loss: 0.4700\n",
            "Epoch [79/300], Loss: 0.6719\n",
            "Epoch [79/300], Loss: 0.7314\n",
            "Epoch [79/300], Loss: 0.6951\n",
            "Epoch [79/300], Loss: 0.8591\n",
            "Epoch [79/300], Loss: 0.7021\n",
            "Epoch [79/300], Loss: 0.6400\n",
            "Epoch [80/300], Loss: 0.8544\n",
            "Epoch [80/300], Loss: 0.7309\n",
            "Epoch [80/300], Loss: 0.7066\n",
            "Epoch [80/300], Loss: 0.6940\n",
            "Epoch [80/300], Loss: 0.6558\n",
            "Epoch [80/300], Loss: 0.6849\n",
            "Epoch [81/300], Loss: 0.7682\n",
            "Epoch [81/300], Loss: 0.6587\n",
            "Epoch [81/300], Loss: 0.7015\n",
            "Epoch [81/300], Loss: 0.7221\n",
            "Epoch [81/300], Loss: 0.7878\n",
            "Epoch [81/300], Loss: 0.9292\n",
            "Epoch [82/300], Loss: 0.7554\n",
            "Epoch [82/300], Loss: 0.6552\n",
            "Epoch [82/300], Loss: 0.7866\n",
            "Epoch [82/300], Loss: 0.7294\n",
            "Epoch [82/300], Loss: 0.7340\n",
            "Epoch [82/300], Loss: 0.2512\n",
            "Epoch [83/300], Loss: 0.6860\n",
            "Epoch [83/300], Loss: 0.6812\n",
            "Epoch [83/300], Loss: 0.8829\n",
            "Epoch [83/300], Loss: 0.7482\n",
            "Epoch [83/300], Loss: 0.6568\n",
            "Epoch [83/300], Loss: 0.6947\n",
            "Epoch [84/300], Loss: 0.7995\n",
            "Epoch [84/300], Loss: 0.7825\n",
            "Epoch [84/300], Loss: 0.7556\n",
            "Epoch [84/300], Loss: 0.5846\n",
            "Epoch [84/300], Loss: 0.7139\n",
            "Epoch [84/300], Loss: 0.6761\n",
            "Epoch [85/300], Loss: 0.6301\n",
            "Epoch [85/300], Loss: 0.7038\n",
            "Epoch [85/300], Loss: 0.8542\n",
            "Epoch [85/300], Loss: 0.6593\n",
            "Epoch [85/300], Loss: 0.7753\n",
            "Epoch [85/300], Loss: 1.2350\n",
            "Epoch [86/300], Loss: 0.6719\n",
            "Epoch [86/300], Loss: 0.7722\n",
            "Epoch [86/300], Loss: 0.6776\n",
            "Epoch [86/300], Loss: 0.7439\n",
            "Epoch [86/300], Loss: 0.7678\n",
            "Epoch [86/300], Loss: 1.3000\n",
            "Epoch [87/300], Loss: 0.7336\n",
            "Epoch [87/300], Loss: 0.7125\n",
            "Epoch [87/300], Loss: 0.7587\n",
            "Epoch [87/300], Loss: 0.6357\n",
            "Epoch [87/300], Loss: 0.7723\n",
            "Epoch [87/300], Loss: 1.1664\n",
            "Epoch [88/300], Loss: 0.7827\n",
            "Epoch [88/300], Loss: 0.7621\n",
            "Epoch [88/300], Loss: 0.7274\n",
            "Epoch [88/300], Loss: 0.7512\n",
            "Epoch [88/300], Loss: 0.6305\n",
            "Epoch [88/300], Loss: 0.2650\n",
            "Epoch [89/300], Loss: 0.7091\n",
            "Epoch [89/300], Loss: 0.7008\n",
            "Epoch [89/300], Loss: 0.7967\n",
            "Epoch [89/300], Loss: 0.7730\n",
            "Epoch [89/300], Loss: 0.6503\n",
            "Epoch [89/300], Loss: 1.0450\n",
            "Epoch [90/300], Loss: 0.7557\n",
            "Epoch [90/300], Loss: 0.7913\n",
            "Epoch [90/300], Loss: 0.6314\n",
            "Epoch [90/300], Loss: 0.6929\n",
            "Epoch [90/300], Loss: 0.7668\n",
            "Epoch [90/300], Loss: 0.6100\n",
            "Epoch [91/300], Loss: 0.7236\n",
            "Epoch [91/300], Loss: 0.7154\n",
            "Epoch [91/300], Loss: 0.7283\n",
            "Epoch [91/300], Loss: 0.7096\n",
            "Epoch [91/300], Loss: 0.7768\n",
            "Epoch [91/300], Loss: 0.7650\n",
            "Epoch [92/300], Loss: 0.7446\n",
            "Epoch [92/300], Loss: 0.7052\n",
            "Epoch [92/300], Loss: 0.6820\n",
            "Epoch [92/300], Loss: 0.7086\n",
            "Epoch [92/300], Loss: 0.7872\n",
            "Epoch [92/300], Loss: 0.5648\n",
            "Epoch [93/300], Loss: 0.6815\n",
            "Epoch [93/300], Loss: 0.6389\n",
            "Epoch [93/300], Loss: 0.7834\n",
            "Epoch [93/300], Loss: 0.7189\n",
            "Epoch [93/300], Loss: 0.7756\n",
            "Epoch [93/300], Loss: 1.0250\n",
            "Epoch [94/300], Loss: 0.8212\n",
            "Epoch [94/300], Loss: 0.7499\n",
            "Epoch [94/300], Loss: 0.7371\n",
            "Epoch [94/300], Loss: 0.5547\n",
            "Epoch [94/300], Loss: 0.7450\n",
            "Epoch [94/300], Loss: 1.2921\n",
            "Epoch [95/300], Loss: 0.6808\n",
            "Epoch [95/300], Loss: 0.8061\n",
            "Epoch [95/300], Loss: 0.8049\n",
            "Epoch [95/300], Loss: 0.6712\n",
            "Epoch [95/300], Loss: 0.6844\n",
            "Epoch [95/300], Loss: 0.7100\n",
            "Epoch [96/300], Loss: 0.7165\n",
            "Epoch [96/300], Loss: 0.7652\n",
            "Epoch [96/300], Loss: 0.7233\n",
            "Epoch [96/300], Loss: 0.6270\n",
            "Epoch [96/300], Loss: 0.7829\n",
            "Epoch [96/300], Loss: 1.2400\n",
            "Epoch [97/300], Loss: 0.7813\n",
            "Epoch [97/300], Loss: 0.7799\n",
            "Epoch [97/300], Loss: 0.6920\n",
            "Epoch [97/300], Loss: 0.7557\n",
            "Epoch [97/300], Loss: 0.6468\n",
            "Epoch [97/300], Loss: 0.8502\n",
            "Epoch [98/300], Loss: 0.7827\n",
            "Epoch [98/300], Loss: 0.6757\n",
            "Epoch [98/300], Loss: 0.8164\n",
            "Epoch [98/300], Loss: 0.7559\n",
            "Epoch [98/300], Loss: 0.5971\n",
            "Epoch [98/300], Loss: 0.7043\n",
            "Epoch [99/300], Loss: 0.7126\n",
            "Epoch [99/300], Loss: 0.7085\n",
            "Epoch [99/300], Loss: 0.7137\n",
            "Epoch [99/300], Loss: 0.7277\n",
            "Epoch [99/300], Loss: 0.7652\n",
            "Epoch [99/300], Loss: 1.0283\n",
            "Epoch [100/300], Loss: 0.6549\n",
            "Epoch [100/300], Loss: 0.6546\n",
            "Epoch [100/300], Loss: 0.7608\n",
            "Epoch [100/300], Loss: 0.8283\n",
            "Epoch [100/300], Loss: 0.7390\n",
            "Epoch [100/300], Loss: 0.7700\n",
            "Epoch [101/300], Loss: 0.7552\n",
            "Epoch [101/300], Loss: 0.7789\n",
            "Epoch [101/300], Loss: 0.6934\n",
            "Epoch [101/300], Loss: 0.7699\n",
            "Epoch [101/300], Loss: 0.6426\n",
            "Epoch [101/300], Loss: 0.6892\n",
            "Epoch [102/300], Loss: 0.6840\n",
            "Epoch [102/300], Loss: 0.6332\n",
            "Epoch [102/300], Loss: 0.8597\n",
            "Epoch [102/300], Loss: 0.6742\n",
            "Epoch [102/300], Loss: 0.7613\n",
            "Epoch [102/300], Loss: 0.8037\n",
            "Epoch [103/300], Loss: 0.7981\n",
            "Epoch [103/300], Loss: 0.7190\n",
            "Epoch [103/300], Loss: 0.8291\n",
            "Epoch [103/300], Loss: 0.5739\n",
            "Epoch [103/300], Loss: 0.7327\n",
            "Epoch [103/300], Loss: 0.1629\n",
            "Epoch [104/300], Loss: 0.7332\n",
            "Epoch [104/300], Loss: 0.7016\n",
            "Epoch [104/300], Loss: 0.7642\n",
            "Epoch [104/300], Loss: 0.6818\n",
            "Epoch [104/300], Loss: 0.7478\n",
            "Epoch [104/300], Loss: 0.7333\n",
            "Epoch [105/300], Loss: 0.7125\n",
            "Epoch [105/300], Loss: 0.5826\n",
            "Epoch [105/300], Loss: 0.7015\n",
            "Epoch [105/300], Loss: 0.8177\n",
            "Epoch [105/300], Loss: 0.8265\n",
            "Epoch [105/300], Loss: 0.6650\n",
            "Epoch [106/300], Loss: 0.8216\n",
            "Epoch [106/300], Loss: 0.7082\n",
            "Epoch [106/300], Loss: 0.6780\n",
            "Epoch [106/300], Loss: 0.6978\n",
            "Epoch [106/300], Loss: 0.6980\n",
            "Epoch [106/300], Loss: 0.4119\n",
            "Epoch [107/300], Loss: 0.7803\n",
            "Epoch [107/300], Loss: 0.6379\n",
            "Epoch [107/300], Loss: 0.7751\n",
            "Epoch [107/300], Loss: 0.7912\n",
            "Epoch [107/300], Loss: 0.6209\n",
            "Epoch [107/300], Loss: 0.9223\n",
            "Epoch [108/300], Loss: 0.7780\n",
            "Epoch [108/300], Loss: 0.7238\n",
            "Epoch [108/300], Loss: 0.6547\n",
            "Epoch [108/300], Loss: 0.7352\n",
            "Epoch [108/300], Loss: 0.7192\n",
            "Epoch [108/300], Loss: 0.2760\n",
            "Epoch [109/300], Loss: 0.7529\n",
            "Epoch [109/300], Loss: 0.7772\n",
            "Epoch [109/300], Loss: 0.6363\n",
            "Epoch [109/300], Loss: 0.7402\n",
            "Epoch [109/300], Loss: 0.7075\n",
            "Epoch [109/300], Loss: 1.1400\n",
            "Epoch [110/300], Loss: 0.6640\n",
            "Epoch [110/300], Loss: 0.7936\n",
            "Epoch [110/300], Loss: 0.7372\n",
            "Epoch [110/300], Loss: 0.6955\n",
            "Epoch [110/300], Loss: 0.7578\n",
            "Epoch [110/300], Loss: 0.3777\n",
            "Epoch [111/300], Loss: 0.6441\n",
            "Epoch [111/300], Loss: 0.8578\n",
            "Epoch [111/300], Loss: 0.7657\n",
            "Epoch [111/300], Loss: 0.6364\n",
            "Epoch [111/300], Loss: 0.6995\n",
            "Epoch [111/300], Loss: 0.9933\n",
            "Epoch [112/300], Loss: 0.7917\n",
            "Epoch [112/300], Loss: 0.6716\n",
            "Epoch [112/300], Loss: 0.6678\n",
            "Epoch [112/300], Loss: 0.7020\n",
            "Epoch [112/300], Loss: 0.7638\n",
            "Epoch [112/300], Loss: 0.9410\n",
            "Epoch [113/300], Loss: 0.7383\n",
            "Epoch [113/300], Loss: 0.7360\n",
            "Epoch [113/300], Loss: 0.7705\n",
            "Epoch [113/300], Loss: 0.6622\n",
            "Epoch [113/300], Loss: 0.6962\n",
            "Epoch [113/300], Loss: 0.3186\n",
            "Epoch [114/300], Loss: 0.7190\n",
            "Epoch [114/300], Loss: 0.7204\n",
            "Epoch [114/300], Loss: 0.6850\n",
            "Epoch [114/300], Loss: 0.7662\n",
            "Epoch [114/300], Loss: 0.7085\n",
            "Epoch [114/300], Loss: 0.9783\n",
            "Epoch [115/300], Loss: 0.8059\n",
            "Epoch [115/300], Loss: 0.8086\n",
            "Epoch [115/300], Loss: 0.7871\n",
            "Epoch [115/300], Loss: 0.5899\n",
            "Epoch [115/300], Loss: 0.6673\n",
            "Epoch [115/300], Loss: 0.3677\n",
            "Epoch [116/300], Loss: 0.7396\n",
            "Epoch [116/300], Loss: 0.7559\n",
            "Epoch [116/300], Loss: 0.6306\n",
            "Epoch [116/300], Loss: 0.7238\n",
            "Epoch [116/300], Loss: 0.7948\n",
            "Epoch [116/300], Loss: 0.3508\n",
            "Epoch [117/300], Loss: 0.7590\n",
            "Epoch [117/300], Loss: 0.6568\n",
            "Epoch [117/300], Loss: 0.6574\n",
            "Epoch [117/300], Loss: 0.7480\n",
            "Epoch [117/300], Loss: 0.7853\n",
            "Epoch [117/300], Loss: 0.8360\n",
            "Epoch [118/300], Loss: 0.8142\n",
            "Epoch [118/300], Loss: 0.5876\n",
            "Epoch [118/300], Loss: 0.7924\n",
            "Epoch [118/300], Loss: 0.7757\n",
            "Epoch [118/300], Loss: 0.6563\n",
            "Epoch [118/300], Loss: 0.5000\n",
            "Epoch [119/300], Loss: 0.7426\n",
            "Epoch [119/300], Loss: 0.7647\n",
            "Epoch [119/300], Loss: 0.6715\n",
            "Epoch [119/300], Loss: 0.8451\n",
            "Epoch [119/300], Loss: 0.5940\n",
            "Epoch [119/300], Loss: 0.4623\n",
            "Epoch [120/300], Loss: 0.6905\n",
            "Epoch [120/300], Loss: 0.7977\n",
            "Epoch [120/300], Loss: 0.6606\n",
            "Epoch [120/300], Loss: 0.7288\n",
            "Epoch [120/300], Loss: 0.7381\n",
            "Epoch [120/300], Loss: 0.8600\n",
            "Epoch [121/300], Loss: 0.7353\n",
            "Epoch [121/300], Loss: 0.7172\n",
            "Epoch [121/300], Loss: 0.6108\n",
            "Epoch [121/300], Loss: 0.7556\n",
            "Epoch [121/300], Loss: 0.8080\n",
            "Epoch [121/300], Loss: 0.5550\n",
            "Epoch [122/300], Loss: 0.7511\n",
            "Epoch [122/300], Loss: 0.7741\n",
            "Epoch [122/300], Loss: 0.7524\n",
            "Epoch [122/300], Loss: 0.5937\n",
            "Epoch [122/300], Loss: 0.7568\n",
            "Epoch [122/300], Loss: 0.6900\n",
            "Epoch [123/300], Loss: 0.7412\n",
            "Epoch [123/300], Loss: 0.7479\n",
            "Epoch [123/300], Loss: 0.6821\n",
            "Epoch [123/300], Loss: 0.7626\n",
            "Epoch [123/300], Loss: 0.6844\n",
            "Epoch [123/300], Loss: 0.7050\n",
            "Epoch [124/300], Loss: 0.7307\n",
            "Epoch [124/300], Loss: 0.7656\n",
            "Epoch [124/300], Loss: 0.7040\n",
            "Epoch [124/300], Loss: 0.7227\n",
            "Epoch [124/300], Loss: 0.7015\n",
            "Epoch [124/300], Loss: 0.6650\n",
            "Epoch [125/300], Loss: 0.7378\n",
            "Epoch [125/300], Loss: 0.6719\n",
            "Epoch [125/300], Loss: 0.6802\n",
            "Epoch [125/300], Loss: 0.7368\n",
            "Epoch [125/300], Loss: 0.7840\n",
            "Epoch [125/300], Loss: 0.9107\n",
            "Epoch [126/300], Loss: 0.6684\n",
            "Epoch [126/300], Loss: 0.7436\n",
            "Epoch [126/300], Loss: 0.8367\n",
            "Epoch [126/300], Loss: 0.6600\n",
            "Epoch [126/300], Loss: 0.7200\n",
            "Epoch [126/300], Loss: 0.2200\n",
            "Epoch [127/300], Loss: 0.7044\n",
            "Epoch [127/300], Loss: 0.7229\n",
            "Epoch [127/300], Loss: 0.7902\n",
            "Epoch [127/300], Loss: 0.6972\n",
            "Epoch [127/300], Loss: 0.6796\n",
            "Epoch [127/300], Loss: 0.4791\n",
            "Epoch [128/300], Loss: 0.7546\n",
            "Epoch [128/300], Loss: 0.6378\n",
            "Epoch [128/300], Loss: 0.7303\n",
            "Epoch [128/300], Loss: 0.6417\n",
            "Epoch [128/300], Loss: 0.8171\n",
            "Epoch [128/300], Loss: 1.6300\n",
            "Epoch [129/300], Loss: 0.8099\n",
            "Epoch [129/300], Loss: 0.6812\n",
            "Epoch [129/300], Loss: 0.8612\n",
            "Epoch [129/300], Loss: 0.7123\n",
            "Epoch [129/300], Loss: 0.5517\n",
            "Epoch [129/300], Loss: 0.2861\n",
            "Epoch [130/300], Loss: 0.7872\n",
            "Epoch [130/300], Loss: 0.7100\n",
            "Epoch [130/300], Loss: 0.6778\n",
            "Epoch [130/300], Loss: 0.7280\n",
            "Epoch [130/300], Loss: 0.6939\n",
            "Epoch [130/300], Loss: 1.2150\n",
            "Epoch [131/300], Loss: 0.6693\n",
            "Epoch [131/300], Loss: 0.7317\n",
            "Epoch [131/300], Loss: 0.7752\n",
            "Epoch [131/300], Loss: 0.6832\n",
            "Epoch [131/300], Loss: 0.7373\n",
            "Epoch [131/300], Loss: 1.0050\n",
            "Epoch [132/300], Loss: 0.6543\n",
            "Epoch [132/300], Loss: 0.8729\n",
            "Epoch [132/300], Loss: 0.6740\n",
            "Epoch [132/300], Loss: 0.6954\n",
            "Epoch [132/300], Loss: 0.7045\n",
            "Epoch [132/300], Loss: 0.4181\n",
            "Epoch [133/300], Loss: 0.6394\n",
            "Epoch [133/300], Loss: 0.5546\n",
            "Epoch [133/300], Loss: 0.7706\n",
            "Epoch [133/300], Loss: 0.7864\n",
            "Epoch [133/300], Loss: 0.8245\n",
            "Epoch [133/300], Loss: 0.4700\n",
            "Epoch [134/300], Loss: 0.7781\n",
            "Epoch [134/300], Loss: 0.6580\n",
            "Epoch [134/300], Loss: 0.7027\n",
            "Epoch [134/300], Loss: 0.8097\n",
            "Epoch [134/300], Loss: 0.6451\n",
            "Epoch [134/300], Loss: 0.8393\n",
            "Epoch [135/300], Loss: 0.8088\n",
            "Epoch [135/300], Loss: 0.7343\n",
            "Epoch [135/300], Loss: 0.7186\n",
            "Epoch [135/300], Loss: 0.6348\n",
            "Epoch [135/300], Loss: 0.6768\n",
            "Epoch [135/300], Loss: 0.9359\n",
            "Epoch [136/300], Loss: 0.6834\n",
            "Epoch [136/300], Loss: 0.8274\n",
            "Epoch [136/300], Loss: 0.6656\n",
            "Epoch [136/300], Loss: 0.7333\n",
            "Epoch [136/300], Loss: 0.6668\n",
            "Epoch [136/300], Loss: 0.9150\n",
            "Epoch [137/300], Loss: 0.8061\n",
            "Epoch [137/300], Loss: 0.7043\n",
            "Epoch [137/300], Loss: 0.7309\n",
            "Epoch [137/300], Loss: 0.6785\n",
            "Epoch [137/300], Loss: 0.6770\n",
            "Epoch [137/300], Loss: 0.4100\n",
            "Epoch [138/300], Loss: 0.7821\n",
            "Epoch [138/300], Loss: 0.6921\n",
            "Epoch [138/300], Loss: 0.7007\n",
            "Epoch [138/300], Loss: 0.6748\n",
            "Epoch [138/300], Loss: 0.7479\n",
            "Epoch [138/300], Loss: 0.3004\n",
            "Epoch [139/300], Loss: 0.7607\n",
            "Epoch [139/300], Loss: 0.7110\n",
            "Epoch [139/300], Loss: 0.6713\n",
            "Epoch [139/300], Loss: 0.6257\n",
            "Epoch [139/300], Loss: 0.8007\n",
            "Epoch [139/300], Loss: 0.9458\n",
            "Epoch [140/300], Loss: 0.7774\n",
            "Epoch [140/300], Loss: 0.6481\n",
            "Epoch [140/300], Loss: 0.7403\n",
            "Epoch [140/300], Loss: 0.7378\n",
            "Epoch [140/300], Loss: 0.6950\n",
            "Epoch [140/300], Loss: 0.2445\n",
            "Epoch [141/300], Loss: 0.7346\n",
            "Epoch [141/300], Loss: 0.6663\n",
            "Epoch [141/300], Loss: 0.6164\n",
            "Epoch [141/300], Loss: 0.8034\n",
            "Epoch [141/300], Loss: 0.7428\n",
            "Epoch [141/300], Loss: 0.9763\n",
            "Epoch [142/300], Loss: 0.7993\n",
            "Epoch [142/300], Loss: 0.6489\n",
            "Epoch [142/300], Loss: 0.6293\n",
            "Epoch [142/300], Loss: 0.7326\n",
            "Epoch [142/300], Loss: 0.8061\n",
            "Epoch [142/300], Loss: 0.3150\n",
            "Epoch [143/300], Loss: 0.6419\n",
            "Epoch [143/300], Loss: 0.7711\n",
            "Epoch [143/300], Loss: 0.6954\n",
            "Epoch [143/300], Loss: 0.7273\n",
            "Epoch [143/300], Loss: 0.7720\n",
            "Epoch [143/300], Loss: 0.5455\n",
            "Epoch [144/300], Loss: 0.6552\n",
            "Epoch [144/300], Loss: 0.7961\n",
            "Epoch [144/300], Loss: 0.7246\n",
            "Epoch [144/300], Loss: 0.7101\n",
            "Epoch [144/300], Loss: 0.7059\n",
            "Epoch [144/300], Loss: 1.0150\n",
            "Epoch [145/300], Loss: 0.7151\n",
            "Epoch [145/300], Loss: 0.8013\n",
            "Epoch [145/300], Loss: 0.6620\n",
            "Epoch [145/300], Loss: 0.7393\n",
            "Epoch [145/300], Loss: 0.6699\n",
            "Epoch [145/300], Loss: 0.4915\n",
            "Epoch [146/300], Loss: 0.8464\n",
            "Epoch [146/300], Loss: 0.6219\n",
            "Epoch [146/300], Loss: 0.7241\n",
            "Epoch [146/300], Loss: 0.7264\n",
            "Epoch [146/300], Loss: 0.6949\n",
            "Epoch [146/300], Loss: 0.3350\n",
            "Epoch [147/300], Loss: 0.7619\n",
            "Epoch [147/300], Loss: 0.7336\n",
            "Epoch [147/300], Loss: 0.8131\n",
            "Epoch [147/300], Loss: 0.6001\n",
            "Epoch [147/300], Loss: 0.6828\n",
            "Epoch [147/300], Loss: 0.8850\n",
            "Epoch [148/300], Loss: 0.7102\n",
            "Epoch [148/300], Loss: 0.7712\n",
            "Epoch [148/300], Loss: 0.6537\n",
            "Epoch [148/300], Loss: 0.6957\n",
            "Epoch [148/300], Loss: 0.7123\n",
            "Epoch [148/300], Loss: 1.4029\n",
            "Epoch [149/300], Loss: 0.6742\n",
            "Epoch [149/300], Loss: 0.6910\n",
            "Epoch [149/300], Loss: 0.7481\n",
            "Epoch [149/300], Loss: 0.7178\n",
            "Epoch [149/300], Loss: 0.7527\n",
            "Epoch [149/300], Loss: 0.4150\n",
            "Epoch [150/300], Loss: 0.6861\n",
            "Epoch [150/300], Loss: 0.7369\n",
            "Epoch [150/300], Loss: 0.7018\n",
            "Epoch [150/300], Loss: 0.7294\n",
            "Epoch [150/300], Loss: 0.7114\n",
            "Epoch [150/300], Loss: 0.7450\n",
            "Epoch [151/300], Loss: 0.7262\n",
            "Epoch [151/300], Loss: 0.7345\n",
            "Epoch [151/300], Loss: 0.6722\n",
            "Epoch [151/300], Loss: 0.6419\n",
            "Epoch [151/300], Loss: 0.7505\n",
            "Epoch [151/300], Loss: 1.3704\n",
            "Epoch [152/300], Loss: 0.6599\n",
            "Epoch [152/300], Loss: 0.6339\n",
            "Epoch [152/300], Loss: 0.7051\n",
            "Epoch [152/300], Loss: 0.7223\n",
            "Epoch [152/300], Loss: 0.8249\n",
            "Epoch [152/300], Loss: 0.7557\n",
            "Epoch [153/300], Loss: 0.6737\n",
            "Epoch [153/300], Loss: 0.7186\n",
            "Epoch [153/300], Loss: 0.6817\n",
            "Epoch [153/300], Loss: 0.7981\n",
            "Epoch [153/300], Loss: 0.7098\n",
            "Epoch [153/300], Loss: 0.3048\n",
            "Epoch [154/300], Loss: 0.7171\n",
            "Epoch [154/300], Loss: 0.5758\n",
            "Epoch [154/300], Loss: 0.7231\n",
            "Epoch [154/300], Loss: 0.8064\n",
            "Epoch [154/300], Loss: 0.7290\n",
            "Epoch [154/300], Loss: 0.8511\n",
            "Epoch [155/300], Loss: 0.6983\n",
            "Epoch [155/300], Loss: 0.6248\n",
            "Epoch [155/300], Loss: 0.7127\n",
            "Epoch [155/300], Loss: 0.6806\n",
            "Epoch [155/300], Loss: 0.8545\n",
            "Epoch [155/300], Loss: 0.4850\n",
            "Epoch [156/300], Loss: 0.7598\n",
            "Epoch [156/300], Loss: 0.7253\n",
            "Epoch [156/300], Loss: 0.8001\n",
            "Epoch [156/300], Loss: 0.6038\n",
            "Epoch [156/300], Loss: 0.6546\n",
            "Epoch [156/300], Loss: 0.5600\n",
            "Epoch [157/300], Loss: 0.7546\n",
            "Epoch [157/300], Loss: 0.7102\n",
            "Epoch [157/300], Loss: 0.7796\n",
            "Epoch [157/300], Loss: 0.6354\n",
            "Epoch [157/300], Loss: 0.6766\n",
            "Epoch [157/300], Loss: 0.7200\n",
            "Epoch [158/300], Loss: 0.7036\n",
            "Epoch [158/300], Loss: 0.6561\n",
            "Epoch [158/300], Loss: 0.6892\n",
            "Epoch [158/300], Loss: 0.7314\n",
            "Epoch [158/300], Loss: 0.7501\n",
            "Epoch [158/300], Loss: 0.9350\n",
            "Epoch [159/300], Loss: 0.7763\n",
            "Epoch [159/300], Loss: 0.6620\n",
            "Epoch [159/300], Loss: 0.7263\n",
            "Epoch [159/300], Loss: 0.7336\n",
            "Epoch [159/300], Loss: 0.6622\n",
            "Epoch [159/300], Loss: 0.4550\n",
            "Epoch [160/300], Loss: 0.6973\n",
            "Epoch [160/300], Loss: 0.6811\n",
            "Epoch [160/300], Loss: 0.7699\n",
            "Epoch [160/300], Loss: 0.7313\n",
            "Epoch [160/300], Loss: 0.6751\n",
            "Epoch [160/300], Loss: 1.0400\n",
            "Epoch [161/300], Loss: 0.7665\n",
            "Epoch [161/300], Loss: 0.6105\n",
            "Epoch [161/300], Loss: 0.7587\n",
            "Epoch [161/300], Loss: 0.7154\n",
            "Epoch [161/300], Loss: 0.7104\n",
            "Epoch [161/300], Loss: 0.7400\n",
            "Epoch [162/300], Loss: 0.7677\n",
            "Epoch [162/300], Loss: 0.6672\n",
            "Epoch [162/300], Loss: 0.6905\n",
            "Epoch [162/300], Loss: 0.7415\n",
            "Epoch [162/300], Loss: 0.6845\n",
            "Epoch [162/300], Loss: 0.7300\n",
            "Epoch [163/300], Loss: 0.7213\n",
            "Epoch [163/300], Loss: 0.7461\n",
            "Epoch [163/300], Loss: 0.5828\n",
            "Epoch [163/300], Loss: 0.7894\n",
            "Epoch [163/300], Loss: 0.7364\n",
            "Epoch [163/300], Loss: 0.4033\n",
            "Epoch [164/300], Loss: 0.8660\n",
            "Epoch [164/300], Loss: 0.6671\n",
            "Epoch [164/300], Loss: 0.6345\n",
            "Epoch [164/300], Loss: 0.7090\n",
            "Epoch [164/300], Loss: 0.6717\n",
            "Epoch [164/300], Loss: 1.1800\n",
            "Epoch [165/300], Loss: 0.6826\n",
            "Epoch [165/300], Loss: 0.6659\n",
            "Epoch [165/300], Loss: 0.7467\n",
            "Epoch [165/300], Loss: 0.7166\n",
            "Epoch [165/300], Loss: 0.7652\n",
            "Epoch [165/300], Loss: 0.0555\n",
            "Epoch [166/300], Loss: 0.6373\n",
            "Epoch [166/300], Loss: 0.6957\n",
            "Epoch [166/300], Loss: 0.6308\n",
            "Epoch [166/300], Loss: 0.7079\n",
            "Epoch [166/300], Loss: 0.8652\n",
            "Epoch [166/300], Loss: 0.5300\n",
            "Epoch [167/300], Loss: 0.7189\n",
            "Epoch [167/300], Loss: 0.7583\n",
            "Epoch [167/300], Loss: 0.6383\n",
            "Epoch [167/300], Loss: 0.8108\n",
            "Epoch [167/300], Loss: 0.6288\n",
            "Epoch [167/300], Loss: 0.8250\n",
            "Epoch [168/300], Loss: 0.7149\n",
            "Epoch [168/300], Loss: 0.6856\n",
            "Epoch [168/300], Loss: 0.6932\n",
            "Epoch [168/300], Loss: 0.8160\n",
            "Epoch [168/300], Loss: 0.6391\n",
            "Epoch [168/300], Loss: 0.4750\n",
            "Epoch [169/300], Loss: 0.6996\n",
            "Epoch [169/300], Loss: 0.8324\n",
            "Epoch [169/300], Loss: 0.6522\n",
            "Epoch [169/300], Loss: 0.6201\n",
            "Epoch [169/300], Loss: 0.7507\n",
            "Epoch [169/300], Loss: 0.7291\n",
            "Epoch [170/300], Loss: 0.7041\n",
            "Epoch [170/300], Loss: 0.7658\n",
            "Epoch [170/300], Loss: 0.8007\n",
            "Epoch [170/300], Loss: 0.5820\n",
            "Epoch [170/300], Loss: 0.6933\n",
            "Epoch [170/300], Loss: 0.5511\n",
            "Epoch [171/300], Loss: 0.6925\n",
            "Epoch [171/300], Loss: 0.6827\n",
            "Epoch [171/300], Loss: 0.7198\n",
            "Epoch [171/300], Loss: 0.7510\n",
            "Epoch [171/300], Loss: 0.7074\n",
            "Epoch [171/300], Loss: 0.6721\n",
            "Epoch [172/300], Loss: 0.7713\n",
            "Epoch [172/300], Loss: 0.6817\n",
            "Epoch [172/300], Loss: 0.6733\n",
            "Epoch [172/300], Loss: 0.7279\n",
            "Epoch [172/300], Loss: 0.7070\n",
            "Epoch [172/300], Loss: 0.3350\n",
            "Epoch [173/300], Loss: 0.6697\n",
            "Epoch [173/300], Loss: 0.6850\n",
            "Epoch [173/300], Loss: 0.6420\n",
            "Epoch [173/300], Loss: 0.7237\n",
            "Epoch [173/300], Loss: 0.8285\n",
            "Epoch [173/300], Loss: 0.4882\n",
            "Epoch [174/300], Loss: 0.8122\n",
            "Epoch [174/300], Loss: 0.6713\n",
            "Epoch [174/300], Loss: 0.6438\n",
            "Epoch [174/300], Loss: 0.6783\n",
            "Epoch [174/300], Loss: 0.7570\n",
            "Epoch [174/300], Loss: 0.5526\n",
            "Epoch [175/300], Loss: 0.7037\n",
            "Epoch [175/300], Loss: 0.5921\n",
            "Epoch [175/300], Loss: 0.7884\n",
            "Epoch [175/300], Loss: 0.7850\n",
            "Epoch [175/300], Loss: 0.6733\n",
            "Epoch [175/300], Loss: 1.0950\n",
            "Epoch [176/300], Loss: 0.6338\n",
            "Epoch [176/300], Loss: 0.7161\n",
            "Epoch [176/300], Loss: 0.8038\n",
            "Epoch [176/300], Loss: 0.7057\n",
            "Epoch [176/300], Loss: 0.6814\n",
            "Epoch [176/300], Loss: 0.5814\n",
            "Epoch [177/300], Loss: 0.6914\n",
            "Epoch [177/300], Loss: 0.6623\n",
            "Epoch [177/300], Loss: 0.6847\n",
            "Epoch [177/300], Loss: 0.7943\n",
            "Epoch [177/300], Loss: 0.7218\n",
            "Epoch [177/300], Loss: 0.6800\n",
            "Epoch [178/300], Loss: 0.6348\n",
            "Epoch [178/300], Loss: 0.6375\n",
            "Epoch [178/300], Loss: 0.8361\n",
            "Epoch [178/300], Loss: 0.7012\n",
            "Epoch [178/300], Loss: 0.7370\n",
            "Epoch [178/300], Loss: 0.8850\n",
            "Epoch [179/300], Loss: 0.6235\n",
            "Epoch [179/300], Loss: 0.8738\n",
            "Epoch [179/300], Loss: 0.6522\n",
            "Epoch [179/300], Loss: 0.7786\n",
            "Epoch [179/300], Loss: 0.6076\n",
            "Epoch [179/300], Loss: 1.0265\n",
            "Epoch [180/300], Loss: 0.7507\n",
            "Epoch [180/300], Loss: 0.6241\n",
            "Epoch [180/300], Loss: 0.8210\n",
            "Epoch [180/300], Loss: 0.6591\n",
            "Epoch [180/300], Loss: 0.6965\n",
            "Epoch [180/300], Loss: 0.3933\n",
            "Epoch [181/300], Loss: 0.6863\n",
            "Epoch [181/300], Loss: 0.6844\n",
            "Epoch [181/300], Loss: 0.6744\n",
            "Epoch [181/300], Loss: 0.7943\n",
            "Epoch [181/300], Loss: 0.7125\n",
            "Epoch [181/300], Loss: 0.7300\n",
            "Epoch [182/300], Loss: 0.7152\n",
            "Epoch [182/300], Loss: 0.7227\n",
            "Epoch [182/300], Loss: 0.6881\n",
            "Epoch [182/300], Loss: 0.7246\n",
            "Epoch [182/300], Loss: 0.7089\n",
            "Epoch [182/300], Loss: 0.3300\n",
            "Epoch [183/300], Loss: 0.8365\n",
            "Epoch [183/300], Loss: 0.6495\n",
            "Epoch [183/300], Loss: 0.6986\n",
            "Epoch [183/300], Loss: 0.7415\n",
            "Epoch [183/300], Loss: 0.6058\n",
            "Epoch [183/300], Loss: 1.0250\n",
            "Epoch [184/300], Loss: 0.6877\n",
            "Epoch [184/300], Loss: 0.7367\n",
            "Epoch [184/300], Loss: 0.6910\n",
            "Epoch [184/300], Loss: 0.6971\n",
            "Epoch [184/300], Loss: 0.7506\n",
            "Epoch [184/300], Loss: 0.6250\n",
            "Epoch [185/300], Loss: 0.7596\n",
            "Epoch [185/300], Loss: 0.7286\n",
            "Epoch [185/300], Loss: 0.6187\n",
            "Epoch [185/300], Loss: 0.8002\n",
            "Epoch [185/300], Loss: 0.6586\n",
            "Epoch [185/300], Loss: 0.1600\n",
            "Epoch [186/300], Loss: 0.7158\n",
            "Epoch [186/300], Loss: 0.7835\n",
            "Epoch [186/300], Loss: 0.6895\n",
            "Epoch [186/300], Loss: 0.5862\n",
            "Epoch [186/300], Loss: 0.7542\n",
            "Epoch [186/300], Loss: 0.5025\n",
            "Epoch [187/300], Loss: 0.6922\n",
            "Epoch [187/300], Loss: 0.7226\n",
            "Epoch [187/300], Loss: 0.6481\n",
            "Epoch [187/300], Loss: 0.7408\n",
            "Epoch [187/300], Loss: 0.7079\n",
            "Epoch [187/300], Loss: 1.1200\n",
            "Epoch [188/300], Loss: 0.7092\n",
            "Epoch [188/300], Loss: 0.6330\n",
            "Epoch [188/300], Loss: 0.7466\n",
            "Epoch [188/300], Loss: 0.7294\n",
            "Epoch [188/300], Loss: 0.7451\n",
            "Epoch [188/300], Loss: 0.2700\n",
            "Epoch [189/300], Loss: 0.6600\n",
            "Epoch [189/300], Loss: 0.6409\n",
            "Epoch [189/300], Loss: 0.7743\n",
            "Epoch [189/300], Loss: 0.7407\n",
            "Epoch [189/300], Loss: 0.7067\n",
            "Epoch [189/300], Loss: 0.6075\n",
            "Epoch [190/300], Loss: 0.6817\n",
            "Epoch [190/300], Loss: 0.8123\n",
            "Epoch [190/300], Loss: 0.6140\n",
            "Epoch [190/300], Loss: 0.7645\n",
            "Epoch [190/300], Loss: 0.6676\n",
            "Epoch [190/300], Loss: 0.4000\n",
            "Epoch [191/300], Loss: 0.7159\n",
            "Epoch [191/300], Loss: 0.6996\n",
            "Epoch [191/300], Loss: 0.6386\n",
            "Epoch [191/300], Loss: 0.8076\n",
            "Epoch [191/300], Loss: 0.6604\n",
            "Epoch [191/300], Loss: 1.0500\n",
            "Epoch [192/300], Loss: 0.7659\n",
            "Epoch [192/300], Loss: 0.5871\n",
            "Epoch [192/300], Loss: 0.7825\n",
            "Epoch [192/300], Loss: 0.7265\n",
            "Epoch [192/300], Loss: 0.6554\n",
            "Epoch [192/300], Loss: 1.1572\n",
            "Epoch [193/300], Loss: 0.7467\n",
            "Epoch [193/300], Loss: 0.7383\n",
            "Epoch [193/300], Loss: 0.6984\n",
            "Epoch [193/300], Loss: 0.6894\n",
            "Epoch [193/300], Loss: 0.6600\n",
            "Epoch [193/300], Loss: 0.9995\n",
            "Epoch [194/300], Loss: 0.6361\n",
            "Epoch [194/300], Loss: 0.7514\n",
            "Epoch [194/300], Loss: 0.7518\n",
            "Epoch [194/300], Loss: 0.6563\n",
            "Epoch [194/300], Loss: 0.7584\n",
            "Epoch [194/300], Loss: 0.2759\n",
            "Epoch [195/300], Loss: 0.8082\n",
            "Epoch [195/300], Loss: 0.6973\n",
            "Epoch [195/300], Loss: 0.6363\n",
            "Epoch [195/300], Loss: 0.6380\n",
            "Epoch [195/300], Loss: 0.7421\n",
            "Epoch [195/300], Loss: 1.0700\n",
            "Epoch [196/300], Loss: 0.7563\n",
            "Epoch [196/300], Loss: 0.6792\n",
            "Epoch [196/300], Loss: 0.7039\n",
            "Epoch [196/300], Loss: 0.6516\n",
            "Epoch [196/300], Loss: 0.7190\n",
            "Epoch [196/300], Loss: 0.3902\n",
            "Epoch [197/300], Loss: 0.6915\n",
            "Epoch [197/300], Loss: 0.6923\n",
            "Epoch [197/300], Loss: 0.5894\n",
            "Epoch [197/300], Loss: 0.6465\n",
            "Epoch [197/300], Loss: 0.9178\n",
            "Epoch [197/300], Loss: 0.7300\n",
            "Epoch [198/300], Loss: 0.6205\n",
            "Epoch [198/300], Loss: 0.8040\n",
            "Epoch [198/300], Loss: 0.6324\n",
            "Epoch [198/300], Loss: 0.6976\n",
            "Epoch [198/300], Loss: 0.7779\n",
            "Epoch [198/300], Loss: 0.7050\n",
            "Epoch [199/300], Loss: 0.6587\n",
            "Epoch [199/300], Loss: 0.7670\n",
            "Epoch [199/300], Loss: 0.6747\n",
            "Epoch [199/300], Loss: 0.7572\n",
            "Epoch [199/300], Loss: 0.7063\n",
            "Epoch [199/300], Loss: 0.3607\n",
            "Epoch [200/300], Loss: 0.6886\n",
            "Epoch [200/300], Loss: 0.7636\n",
            "Epoch [200/300], Loss: 0.6830\n",
            "Epoch [200/300], Loss: 0.7280\n",
            "Epoch [200/300], Loss: 0.6818\n",
            "Epoch [200/300], Loss: 0.6248\n",
            "Epoch [201/300], Loss: 0.6964\n",
            "Epoch [201/300], Loss: 0.7324\n",
            "Epoch [201/300], Loss: 0.6941\n",
            "Epoch [201/300], Loss: 0.7600\n",
            "Epoch [201/300], Loss: 0.6572\n",
            "Epoch [201/300], Loss: 0.8100\n",
            "Epoch [202/300], Loss: 0.7726\n",
            "Epoch [202/300], Loss: 0.6021\n",
            "Epoch [202/300], Loss: 0.6851\n",
            "Epoch [202/300], Loss: 0.7181\n",
            "Epoch [202/300], Loss: 0.7660\n",
            "Epoch [202/300], Loss: 0.7650\n",
            "Epoch [203/300], Loss: 0.7328\n",
            "Epoch [203/300], Loss: 0.7368\n",
            "Epoch [203/300], Loss: 0.7049\n",
            "Epoch [203/300], Loss: 0.6918\n",
            "Epoch [203/300], Loss: 0.6681\n",
            "Epoch [203/300], Loss: 0.9650\n",
            "Epoch [204/300], Loss: 0.7116\n",
            "Epoch [204/300], Loss: 0.6644\n",
            "Epoch [204/300], Loss: 0.6639\n",
            "Epoch [204/300], Loss: 0.7566\n",
            "Epoch [204/300], Loss: 0.7329\n",
            "Epoch [204/300], Loss: 0.9000\n",
            "Epoch [205/300], Loss: 0.6766\n",
            "Epoch [205/300], Loss: 0.6918\n",
            "Epoch [205/300], Loss: 0.7732\n",
            "Epoch [205/300], Loss: 0.6859\n",
            "Epoch [205/300], Loss: 0.7211\n",
            "Epoch [205/300], Loss: 0.5413\n",
            "Epoch [206/300], Loss: 0.7197\n",
            "Epoch [206/300], Loss: 0.6822\n",
            "Epoch [206/300], Loss: 0.7329\n",
            "Epoch [206/300], Loss: 0.6425\n",
            "Epoch [206/300], Loss: 0.7349\n",
            "Epoch [206/300], Loss: 1.1104\n",
            "Epoch [207/300], Loss: 0.7761\n",
            "Epoch [207/300], Loss: 0.6394\n",
            "Epoch [207/300], Loss: 0.7441\n",
            "Epoch [207/300], Loss: 0.7107\n",
            "Epoch [207/300], Loss: 0.6469\n",
            "Epoch [207/300], Loss: 0.9713\n",
            "Epoch [208/300], Loss: 0.7535\n",
            "Epoch [208/300], Loss: 0.6207\n",
            "Epoch [208/300], Loss: 0.6779\n",
            "Epoch [208/300], Loss: 0.7599\n",
            "Epoch [208/300], Loss: 0.7011\n",
            "Epoch [208/300], Loss: 0.6750\n",
            "Epoch [209/300], Loss: 0.7183\n",
            "Epoch [209/300], Loss: 0.7333\n",
            "Epoch [209/300], Loss: 0.7955\n",
            "Epoch [209/300], Loss: 0.6173\n",
            "Epoch [209/300], Loss: 0.6622\n",
            "Epoch [209/300], Loss: 0.7633\n",
            "Epoch [210/300], Loss: 0.7292\n",
            "Epoch [210/300], Loss: 0.7291\n",
            "Epoch [210/300], Loss: 0.6877\n",
            "Epoch [210/300], Loss: 0.6137\n",
            "Epoch [210/300], Loss: 0.7357\n",
            "Epoch [210/300], Loss: 1.5450\n",
            "Epoch [211/300], Loss: 0.7772\n",
            "Epoch [211/300], Loss: 0.7052\n",
            "Epoch [211/300], Loss: 0.7870\n",
            "Epoch [211/300], Loss: 0.5957\n",
            "Epoch [211/300], Loss: 0.6720\n",
            "Epoch [211/300], Loss: 0.6700\n",
            "Epoch [212/300], Loss: 0.7866\n",
            "Epoch [212/300], Loss: 0.7136\n",
            "Epoch [212/300], Loss: 0.6808\n",
            "Epoch [212/300], Loss: 0.6071\n",
            "Epoch [212/300], Loss: 0.7630\n",
            "Epoch [212/300], Loss: 0.3050\n",
            "Epoch [213/300], Loss: 0.8279\n",
            "Epoch [213/300], Loss: 0.6661\n",
            "Epoch [213/300], Loss: 0.7507\n",
            "Epoch [213/300], Loss: 0.6605\n",
            "Epoch [213/300], Loss: 0.6402\n",
            "Epoch [213/300], Loss: 0.6136\n",
            "Epoch [214/300], Loss: 0.6182\n",
            "Epoch [214/300], Loss: 0.6745\n",
            "Epoch [214/300], Loss: 0.7398\n",
            "Epoch [214/300], Loss: 0.7540\n",
            "Epoch [214/300], Loss: 0.7228\n",
            "Epoch [214/300], Loss: 0.3559\n",
            "Epoch [215/300], Loss: 0.6293\n",
            "Epoch [215/300], Loss: 0.7322\n",
            "Epoch [215/300], Loss: 0.7569\n",
            "Epoch [215/300], Loss: 0.7299\n",
            "Epoch [215/300], Loss: 0.7143\n",
            "Epoch [215/300], Loss: 0.1211\n",
            "Epoch [216/300], Loss: 0.7933\n",
            "Epoch [216/300], Loss: 0.6632\n",
            "Epoch [216/300], Loss: 0.6476\n",
            "Epoch [216/300], Loss: 0.8116\n",
            "Epoch [216/300], Loss: 0.6239\n",
            "Epoch [216/300], Loss: 0.3300\n",
            "Epoch [217/300], Loss: 0.6289\n",
            "Epoch [217/300], Loss: 0.7276\n",
            "Epoch [217/300], Loss: 0.7453\n",
            "Epoch [217/300], Loss: 0.7422\n",
            "Epoch [217/300], Loss: 0.7008\n",
            "Epoch [217/300], Loss: 0.1050\n",
            "Epoch [218/300], Loss: 0.7375\n",
            "Epoch [218/300], Loss: 0.7457\n",
            "Epoch [218/300], Loss: 0.6834\n",
            "Epoch [218/300], Loss: 0.6968\n",
            "Epoch [218/300], Loss: 0.6730\n",
            "Epoch [218/300], Loss: 0.7000\n",
            "Epoch [219/300], Loss: 0.6550\n",
            "Epoch [219/300], Loss: 0.6625\n",
            "Epoch [219/300], Loss: 0.7722\n",
            "Epoch [219/300], Loss: 0.6882\n",
            "Epoch [219/300], Loss: 0.7523\n",
            "Epoch [219/300], Loss: 0.8350\n",
            "Epoch [220/300], Loss: 0.7360\n",
            "Epoch [220/300], Loss: 0.6208\n",
            "Epoch [220/300], Loss: 0.6265\n",
            "Epoch [220/300], Loss: 0.8189\n",
            "Epoch [220/300], Loss: 0.7287\n",
            "Epoch [220/300], Loss: 0.4077\n",
            "Epoch [221/300], Loss: 0.5795\n",
            "Epoch [221/300], Loss: 0.7260\n",
            "Epoch [221/300], Loss: 0.7712\n",
            "Epoch [221/300], Loss: 0.7382\n",
            "Epoch [221/300], Loss: 0.7159\n",
            "Epoch [221/300], Loss: 0.7480\n",
            "Epoch [222/300], Loss: 0.7355\n",
            "Epoch [222/300], Loss: 0.6358\n",
            "Epoch [222/300], Loss: 0.6705\n",
            "Epoch [222/300], Loss: 0.7128\n",
            "Epoch [222/300], Loss: 0.7871\n",
            "Epoch [222/300], Loss: 0.5836\n",
            "Epoch [223/300], Loss: 0.7136\n",
            "Epoch [223/300], Loss: 0.7159\n",
            "Epoch [223/300], Loss: 0.6436\n",
            "Epoch [223/300], Loss: 0.7883\n",
            "Epoch [223/300], Loss: 0.6557\n",
            "Epoch [223/300], Loss: 0.7350\n",
            "Epoch [224/300], Loss: 0.7647\n",
            "Epoch [224/300], Loss: 0.7205\n",
            "Epoch [224/300], Loss: 0.7230\n",
            "Epoch [224/300], Loss: 0.7116\n",
            "Epoch [224/300], Loss: 0.6272\n",
            "Epoch [224/300], Loss: 0.4735\n",
            "Epoch [225/300], Loss: 0.6598\n",
            "Epoch [225/300], Loss: 0.7035\n",
            "Epoch [225/300], Loss: 0.6933\n",
            "Epoch [225/300], Loss: 0.6751\n",
            "Epoch [225/300], Loss: 0.7740\n",
            "Epoch [225/300], Loss: 1.3000\n",
            "Epoch [226/300], Loss: 0.8064\n",
            "Epoch [226/300], Loss: 0.6907\n",
            "Epoch [226/300], Loss: 0.6501\n",
            "Epoch [226/300], Loss: 0.6871\n",
            "Epoch [226/300], Loss: 0.6619\n",
            "Epoch [226/300], Loss: 1.4382\n",
            "Epoch [227/300], Loss: 0.7441\n",
            "Epoch [227/300], Loss: 0.7243\n",
            "Epoch [227/300], Loss: 0.6583\n",
            "Epoch [227/300], Loss: 0.7478\n",
            "Epoch [227/300], Loss: 0.6702\n",
            "Epoch [227/300], Loss: 0.6350\n",
            "Epoch [228/300], Loss: 0.6878\n",
            "Epoch [228/300], Loss: 0.7697\n",
            "Epoch [228/300], Loss: 0.6571\n",
            "Epoch [228/300], Loss: 0.6614\n",
            "Epoch [228/300], Loss: 0.7788\n",
            "Epoch [228/300], Loss: 0.2055\n",
            "Epoch [229/300], Loss: 0.7247\n",
            "Epoch [229/300], Loss: 0.6436\n",
            "Epoch [229/300], Loss: 0.7373\n",
            "Epoch [229/300], Loss: 0.7243\n",
            "Epoch [229/300], Loss: 0.7169\n",
            "Epoch [229/300], Loss: 0.1966\n",
            "Epoch [230/300], Loss: 0.6699\n",
            "Epoch [230/300], Loss: 0.6365\n",
            "Epoch [230/300], Loss: 0.7713\n",
            "Epoch [230/300], Loss: 0.6703\n",
            "Epoch [230/300], Loss: 0.7657\n",
            "Epoch [230/300], Loss: 1.1100\n",
            "Epoch [231/300], Loss: 0.7156\n",
            "Epoch [231/300], Loss: 0.6830\n",
            "Epoch [231/300], Loss: 0.6954\n",
            "Epoch [231/300], Loss: 0.7082\n",
            "Epoch [231/300], Loss: 0.7270\n",
            "Epoch [231/300], Loss: 0.5536\n",
            "Epoch [232/300], Loss: 0.7627\n",
            "Epoch [232/300], Loss: 0.6814\n",
            "Epoch [232/300], Loss: 0.6876\n",
            "Epoch [232/300], Loss: 0.6698\n",
            "Epoch [232/300], Loss: 0.7533\n",
            "Epoch [232/300], Loss: 0.4000\n",
            "Epoch [233/300], Loss: 0.6019\n",
            "Epoch [233/300], Loss: 0.7334\n",
            "Epoch [233/300], Loss: 0.7117\n",
            "Epoch [233/300], Loss: 0.7408\n",
            "Epoch [233/300], Loss: 0.7477\n",
            "Epoch [233/300], Loss: 0.7450\n",
            "Epoch [234/300], Loss: 0.6289\n",
            "Epoch [234/300], Loss: 0.7740\n",
            "Epoch [234/300], Loss: 0.7740\n",
            "Epoch [234/300], Loss: 0.7486\n",
            "Epoch [234/300], Loss: 0.6183\n",
            "Epoch [234/300], Loss: 0.7600\n",
            "Epoch [235/300], Loss: 0.6561\n",
            "Epoch [235/300], Loss: 0.6661\n",
            "Epoch [235/300], Loss: 0.6737\n",
            "Epoch [235/300], Loss: 0.7196\n",
            "Epoch [235/300], Loss: 0.7694\n",
            "Epoch [235/300], Loss: 1.0550\n",
            "Epoch [236/300], Loss: 0.6799\n",
            "Epoch [236/300], Loss: 0.6665\n",
            "Epoch [236/300], Loss: 0.6902\n",
            "Epoch [236/300], Loss: 0.6848\n",
            "Epoch [236/300], Loss: 0.8289\n",
            "Epoch [236/300], Loss: 0.3739\n",
            "Epoch [237/300], Loss: 0.7740\n",
            "Epoch [237/300], Loss: 0.5823\n",
            "Epoch [237/300], Loss: 0.6852\n",
            "Epoch [237/300], Loss: 0.7451\n",
            "Epoch [237/300], Loss: 0.7185\n",
            "Epoch [237/300], Loss: 0.6680\n",
            "Epoch [238/300], Loss: 0.6559\n",
            "Epoch [238/300], Loss: 0.7419\n",
            "Epoch [238/300], Loss: 0.7292\n",
            "Epoch [238/300], Loss: 0.7112\n",
            "Epoch [238/300], Loss: 0.7042\n",
            "Epoch [238/300], Loss: 0.4196\n",
            "Epoch [239/300], Loss: 0.7088\n",
            "Epoch [239/300], Loss: 0.6729\n",
            "Epoch [239/300], Loss: 0.7594\n",
            "Epoch [239/300], Loss: 0.7076\n",
            "Epoch [239/300], Loss: 0.6833\n",
            "Epoch [239/300], Loss: 0.2950\n",
            "Epoch [240/300], Loss: 0.6078\n",
            "Epoch [240/300], Loss: 0.7842\n",
            "Epoch [240/300], Loss: 0.7684\n",
            "Epoch [240/300], Loss: 0.6483\n",
            "Epoch [240/300], Loss: 0.7317\n",
            "Epoch [240/300], Loss: 0.2542\n",
            "Epoch [241/300], Loss: 0.7000\n",
            "Epoch [241/300], Loss: 0.6891\n",
            "Epoch [241/300], Loss: 0.7261\n",
            "Epoch [241/300], Loss: 0.6776\n",
            "Epoch [241/300], Loss: 0.7533\n",
            "Epoch [241/300], Loss: 0.2138\n",
            "Epoch [242/300], Loss: 0.7316\n",
            "Epoch [242/300], Loss: 0.7404\n",
            "Epoch [242/300], Loss: 0.7825\n",
            "Epoch [242/300], Loss: 0.6462\n",
            "Epoch [242/300], Loss: 0.6311\n",
            "Epoch [242/300], Loss: 0.4700\n",
            "Epoch [243/300], Loss: 0.6214\n",
            "Epoch [243/300], Loss: 0.7639\n",
            "Epoch [243/300], Loss: 0.6641\n",
            "Epoch [243/300], Loss: 0.7013\n",
            "Epoch [243/300], Loss: 0.7774\n",
            "Epoch [243/300], Loss: 0.4632\n",
            "Epoch [244/300], Loss: 0.7677\n",
            "Epoch [244/300], Loss: 0.7691\n",
            "Epoch [244/300], Loss: 0.7075\n",
            "Epoch [244/300], Loss: 0.6900\n",
            "Epoch [244/300], Loss: 0.6073\n",
            "Epoch [244/300], Loss: 0.2200\n",
            "Epoch [245/300], Loss: 0.7035\n",
            "Epoch [245/300], Loss: 0.6863\n",
            "Epoch [245/300], Loss: 0.6527\n",
            "Epoch [245/300], Loss: 0.6728\n",
            "Epoch [245/300], Loss: 0.8143\n",
            "Epoch [245/300], Loss: 0.6763\n",
            "Epoch [246/300], Loss: 0.7376\n",
            "Epoch [246/300], Loss: 0.6820\n",
            "Epoch [246/300], Loss: 0.7419\n",
            "Epoch [246/300], Loss: 0.6756\n",
            "Epoch [246/300], Loss: 0.7041\n",
            "Epoch [246/300], Loss: 0.3100\n",
            "Epoch [247/300], Loss: 0.6917\n",
            "Epoch [247/300], Loss: 0.7158\n",
            "Epoch [247/300], Loss: 0.6480\n",
            "Epoch [247/300], Loss: 0.7351\n",
            "Epoch [247/300], Loss: 0.6850\n",
            "Epoch [247/300], Loss: 0.9609\n",
            "Epoch [248/300], Loss: 0.7229\n",
            "Epoch [248/300], Loss: 0.7134\n",
            "Epoch [248/300], Loss: 0.5887\n",
            "Epoch [248/300], Loss: 0.6766\n",
            "Epoch [248/300], Loss: 0.8274\n",
            "Epoch [248/300], Loss: 0.4247\n",
            "Epoch [249/300], Loss: 0.6696\n",
            "Epoch [249/300], Loss: 0.7187\n",
            "Epoch [249/300], Loss: 0.6774\n",
            "Epoch [249/300], Loss: 0.7131\n",
            "Epoch [249/300], Loss: 0.7628\n",
            "Epoch [249/300], Loss: 0.3378\n",
            "Epoch [250/300], Loss: 0.7069\n",
            "Epoch [250/300], Loss: 0.7302\n",
            "Epoch [250/300], Loss: 0.6212\n",
            "Epoch [250/300], Loss: 0.7328\n",
            "Epoch [250/300], Loss: 0.7332\n",
            "Epoch [250/300], Loss: 0.8600\n",
            "Epoch [251/300], Loss: 0.7149\n",
            "Epoch [251/300], Loss: 0.5651\n",
            "Epoch [251/300], Loss: 0.7365\n",
            "Epoch [251/300], Loss: 0.7109\n",
            "Epoch [251/300], Loss: 0.7992\n",
            "Epoch [251/300], Loss: 0.6102\n",
            "Epoch [252/300], Loss: 0.8086\n",
            "Epoch [252/300], Loss: 0.6104\n",
            "Epoch [252/300], Loss: 0.6941\n",
            "Epoch [252/300], Loss: 0.6532\n",
            "Epoch [252/300], Loss: 0.7796\n",
            "Epoch [252/300], Loss: 0.5400\n",
            "Epoch [253/300], Loss: 0.6948\n",
            "Epoch [253/300], Loss: 0.6024\n",
            "Epoch [253/300], Loss: 0.7121\n",
            "Epoch [253/300], Loss: 0.7491\n",
            "Epoch [253/300], Loss: 0.7724\n",
            "Epoch [253/300], Loss: 0.6450\n",
            "Epoch [254/300], Loss: 0.6899\n",
            "Epoch [254/300], Loss: 0.7170\n",
            "Epoch [254/300], Loss: 0.7714\n",
            "Epoch [254/300], Loss: 0.7065\n",
            "Epoch [254/300], Loss: 0.6416\n",
            "Epoch [254/300], Loss: 0.7350\n",
            "Epoch [255/300], Loss: 0.6785\n",
            "Epoch [255/300], Loss: 0.6348\n",
            "Epoch [255/300], Loss: 0.6348\n",
            "Epoch [255/300], Loss: 0.7507\n",
            "Epoch [255/300], Loss: 0.8201\n",
            "Epoch [255/300], Loss: 0.8281\n",
            "Epoch [256/300], Loss: 0.7132\n",
            "Epoch [256/300], Loss: 0.6954\n",
            "Epoch [256/300], Loss: 0.7652\n",
            "Epoch [256/300], Loss: 0.6006\n",
            "Epoch [256/300], Loss: 0.7299\n",
            "Epoch [256/300], Loss: 1.0646\n",
            "Epoch [257/300], Loss: 0.7188\n",
            "Epoch [257/300], Loss: 0.6415\n",
            "Epoch [257/300], Loss: 0.7384\n",
            "Epoch [257/300], Loss: 0.7874\n",
            "Epoch [257/300], Loss: 0.6522\n",
            "Epoch [257/300], Loss: 0.2845\n",
            "Epoch [258/300], Loss: 0.6176\n",
            "Epoch [258/300], Loss: 0.7643\n",
            "Epoch [258/300], Loss: 0.7662\n",
            "Epoch [258/300], Loss: 0.7382\n",
            "Epoch [258/300], Loss: 0.6297\n",
            "Epoch [258/300], Loss: 0.8600\n",
            "Epoch [259/300], Loss: 0.7765\n",
            "Epoch [259/300], Loss: 0.7507\n",
            "Epoch [259/300], Loss: 0.7469\n",
            "Epoch [259/300], Loss: 0.6109\n",
            "Epoch [259/300], Loss: 0.6382\n",
            "Epoch [259/300], Loss: 0.8253\n",
            "Epoch [260/300], Loss: 0.7101\n",
            "Epoch [260/300], Loss: 0.7327\n",
            "Epoch [260/300], Loss: 0.6947\n",
            "Epoch [260/300], Loss: 0.6520\n",
            "Epoch [260/300], Loss: 0.7364\n",
            "Epoch [260/300], Loss: 0.6737\n",
            "Epoch [261/300], Loss: 0.8283\n",
            "Epoch [261/300], Loss: 0.7032\n",
            "Epoch [261/300], Loss: 0.6889\n",
            "Epoch [261/300], Loss: 0.7124\n",
            "Epoch [261/300], Loss: 0.5981\n",
            "Epoch [261/300], Loss: 0.2368\n",
            "Epoch [262/300], Loss: 0.6470\n",
            "Epoch [262/300], Loss: 0.6918\n",
            "Epoch [262/300], Loss: 0.6727\n",
            "Epoch [262/300], Loss: 0.6978\n",
            "Epoch [262/300], Loss: 0.8109\n",
            "Epoch [262/300], Loss: 0.3663\n",
            "Epoch [263/300], Loss: 0.6828\n",
            "Epoch [263/300], Loss: 0.6943\n",
            "Epoch [263/300], Loss: 0.8327\n",
            "Epoch [263/300], Loss: 0.6124\n",
            "Epoch [263/300], Loss: 0.6814\n",
            "Epoch [263/300], Loss: 0.6378\n",
            "Epoch [264/300], Loss: 0.7465\n",
            "Epoch [264/300], Loss: 0.5915\n",
            "Epoch [264/300], Loss: 0.7162\n",
            "Epoch [264/300], Loss: 0.7298\n",
            "Epoch [264/300], Loss: 0.7191\n",
            "Epoch [264/300], Loss: 1.1200\n",
            "Epoch [265/300], Loss: 0.6617\n",
            "Epoch [265/300], Loss: 0.6786\n",
            "Epoch [265/300], Loss: 0.6659\n",
            "Epoch [265/300], Loss: 0.7408\n",
            "Epoch [265/300], Loss: 0.7633\n",
            "Epoch [265/300], Loss: 0.6365\n",
            "Epoch [266/300], Loss: 0.6902\n",
            "Epoch [266/300], Loss: 0.5987\n",
            "Epoch [266/300], Loss: 0.8025\n",
            "Epoch [266/300], Loss: 0.7104\n",
            "Epoch [266/300], Loss: 0.7373\n",
            "Epoch [266/300], Loss: 0.2095\n",
            "Epoch [267/300], Loss: 0.6199\n",
            "Epoch [267/300], Loss: 0.6620\n",
            "Epoch [267/300], Loss: 0.7167\n",
            "Epoch [267/300], Loss: 0.7798\n",
            "Epoch [267/300], Loss: 0.7539\n",
            "Epoch [267/300], Loss: 0.5603\n",
            "Epoch [268/300], Loss: 0.6190\n",
            "Epoch [268/300], Loss: 0.6707\n",
            "Epoch [268/300], Loss: 0.6343\n",
            "Epoch [268/300], Loss: 0.8220\n",
            "Epoch [268/300], Loss: 0.7677\n",
            "Epoch [268/300], Loss: 1.1100\n",
            "Epoch [269/300], Loss: 0.7243\n",
            "Epoch [269/300], Loss: 0.7579\n",
            "Epoch [269/300], Loss: 0.6808\n",
            "Epoch [269/300], Loss: 0.7251\n",
            "Epoch [269/300], Loss: 0.6487\n",
            "Epoch [269/300], Loss: 0.9750\n",
            "Epoch [270/300], Loss: 0.5512\n",
            "Epoch [270/300], Loss: 0.6645\n",
            "Epoch [270/300], Loss: 0.7348\n",
            "Epoch [270/300], Loss: 0.8641\n",
            "Epoch [270/300], Loss: 0.7104\n",
            "Epoch [270/300], Loss: 0.6258\n",
            "Epoch [271/300], Loss: 0.6698\n",
            "Epoch [271/300], Loss: 0.7382\n",
            "Epoch [271/300], Loss: 0.6941\n",
            "Epoch [271/300], Loss: 0.7025\n",
            "Epoch [271/300], Loss: 0.7184\n",
            "Epoch [271/300], Loss: 0.4741\n",
            "Epoch [272/300], Loss: 0.7505\n",
            "Epoch [272/300], Loss: 0.6911\n",
            "Epoch [272/300], Loss: 0.6265\n",
            "Epoch [272/300], Loss: 0.7189\n",
            "Epoch [272/300], Loss: 0.7314\n",
            "Epoch [272/300], Loss: 0.9024\n",
            "Epoch [273/300], Loss: 0.6974\n",
            "Epoch [273/300], Loss: 0.8029\n",
            "Epoch [273/300], Loss: 0.7766\n",
            "Epoch [273/300], Loss: 0.6540\n",
            "Epoch [273/300], Loss: 0.5749\n",
            "Epoch [273/300], Loss: 1.1000\n",
            "Epoch [274/300], Loss: 0.7692\n",
            "Epoch [274/300], Loss: 0.6788\n",
            "Epoch [274/300], Loss: 0.6332\n",
            "Epoch [274/300], Loss: 0.6550\n",
            "Epoch [274/300], Loss: 0.7841\n",
            "Epoch [274/300], Loss: 0.6556\n",
            "Epoch [275/300], Loss: 0.7417\n",
            "Epoch [275/300], Loss: 0.5822\n",
            "Epoch [275/300], Loss: 0.7528\n",
            "Epoch [275/300], Loss: 0.6991\n",
            "Epoch [275/300], Loss: 0.7458\n",
            "Epoch [275/300], Loss: 0.6600\n",
            "Epoch [276/300], Loss: 0.6805\n",
            "Epoch [276/300], Loss: 0.7054\n",
            "Epoch [276/300], Loss: 0.7477\n",
            "Epoch [276/300], Loss: 0.6531\n",
            "Epoch [276/300], Loss: 0.7289\n",
            "Epoch [276/300], Loss: 0.7038\n",
            "Epoch [277/300], Loss: 0.7016\n",
            "Epoch [277/300], Loss: 0.6736\n",
            "Epoch [277/300], Loss: 0.7090\n",
            "Epoch [277/300], Loss: 0.7783\n",
            "Epoch [277/300], Loss: 0.6629\n",
            "Epoch [277/300], Loss: 0.5316\n",
            "Epoch [278/300], Loss: 0.6939\n",
            "Epoch [278/300], Loss: 0.6914\n",
            "Epoch [278/300], Loss: 0.6405\n",
            "Epoch [278/300], Loss: 0.8224\n",
            "Epoch [278/300], Loss: 0.6379\n",
            "Epoch [278/300], Loss: 1.0500\n",
            "Epoch [279/300], Loss: 0.7682\n",
            "Epoch [279/300], Loss: 0.6529\n",
            "Epoch [279/300], Loss: 0.7536\n",
            "Epoch [279/300], Loss: 0.6637\n",
            "Epoch [279/300], Loss: 0.6836\n",
            "Epoch [279/300], Loss: 0.5100\n",
            "Epoch [280/300], Loss: 0.7413\n",
            "Epoch [280/300], Loss: 0.5978\n",
            "Epoch [280/300], Loss: 0.7364\n",
            "Epoch [280/300], Loss: 0.6970\n",
            "Epoch [280/300], Loss: 0.7433\n",
            "Epoch [280/300], Loss: 0.7900\n",
            "Epoch [281/300], Loss: 0.7786\n",
            "Epoch [281/300], Loss: 0.5623\n",
            "Epoch [281/300], Loss: 0.6612\n",
            "Epoch [281/300], Loss: 0.7349\n",
            "Epoch [281/300], Loss: 0.7818\n",
            "Epoch [281/300], Loss: 0.5359\n",
            "Epoch [282/300], Loss: 0.6528\n",
            "Epoch [282/300], Loss: 0.7279\n",
            "Epoch [282/300], Loss: 0.6959\n",
            "Epoch [282/300], Loss: 0.7650\n",
            "Epoch [282/300], Loss: 0.6582\n",
            "Epoch [282/300], Loss: 1.2629\n",
            "Epoch [283/300], Loss: 0.6860\n",
            "Epoch [283/300], Loss: 0.7145\n",
            "Epoch [283/300], Loss: 0.7827\n",
            "Epoch [283/300], Loss: 0.5784\n",
            "Epoch [283/300], Loss: 0.7740\n",
            "Epoch [283/300], Loss: 0.3700\n",
            "Epoch [284/300], Loss: 0.5742\n",
            "Epoch [284/300], Loss: 0.6080\n",
            "Epoch [284/300], Loss: 0.7714\n",
            "Epoch [284/300], Loss: 0.7137\n",
            "Epoch [284/300], Loss: 0.7975\n",
            "Epoch [284/300], Loss: 1.3989\n",
            "Epoch [285/300], Loss: 0.7592\n",
            "Epoch [285/300], Loss: 0.7170\n",
            "Epoch [285/300], Loss: 0.7828\n",
            "Epoch [285/300], Loss: 0.6174\n",
            "Epoch [285/300], Loss: 0.6452\n",
            "Epoch [285/300], Loss: 0.6850\n",
            "Epoch [286/300], Loss: 0.6578\n",
            "Epoch [286/300], Loss: 0.7372\n",
            "Epoch [286/300], Loss: 0.7730\n",
            "Epoch [286/300], Loss: 0.6735\n",
            "Epoch [286/300], Loss: 0.6716\n",
            "Epoch [286/300], Loss: 0.8350\n",
            "Epoch [287/300], Loss: 0.7221\n",
            "Epoch [287/300], Loss: 0.8204\n",
            "Epoch [287/300], Loss: 0.7225\n",
            "Epoch [287/300], Loss: 0.6125\n",
            "Epoch [287/300], Loss: 0.6515\n",
            "Epoch [287/300], Loss: 0.4284\n",
            "Epoch [288/300], Loss: 0.7401\n",
            "Epoch [288/300], Loss: 0.8492\n",
            "Epoch [288/300], Loss: 0.5847\n",
            "Epoch [288/300], Loss: 0.6668\n",
            "Epoch [288/300], Loss: 0.6927\n",
            "Epoch [288/300], Loss: 0.3501\n",
            "Epoch [289/300], Loss: 0.7327\n",
            "Epoch [289/300], Loss: 0.7189\n",
            "Epoch [289/300], Loss: 0.7266\n",
            "Epoch [289/300], Loss: 0.6861\n",
            "Epoch [289/300], Loss: 0.6481\n",
            "Epoch [289/300], Loss: 0.6950\n",
            "Epoch [290/300], Loss: 0.6001\n",
            "Epoch [290/300], Loss: 0.7186\n",
            "Epoch [290/300], Loss: 0.7759\n",
            "Epoch [290/300], Loss: 0.7361\n",
            "Epoch [290/300], Loss: 0.6444\n",
            "Epoch [290/300], Loss: 1.3222\n",
            "Epoch [291/300], Loss: 0.7607\n",
            "Epoch [291/300], Loss: 0.6285\n",
            "Epoch [291/300], Loss: 0.7390\n",
            "Epoch [291/300], Loss: 0.6206\n",
            "Epoch [291/300], Loss: 0.7691\n",
            "Epoch [291/300], Loss: 0.7758\n",
            "Epoch [292/300], Loss: 0.7304\n",
            "Epoch [292/300], Loss: 0.7086\n",
            "Epoch [292/300], Loss: 0.7561\n",
            "Epoch [292/300], Loss: 0.6541\n",
            "Epoch [292/300], Loss: 0.6220\n",
            "Epoch [292/300], Loss: 1.4350\n",
            "Epoch [293/300], Loss: 0.6855\n",
            "Epoch [293/300], Loss: 0.7182\n",
            "Epoch [293/300], Loss: 0.7285\n",
            "Epoch [293/300], Loss: 0.6998\n",
            "Epoch [293/300], Loss: 0.6969\n",
            "Epoch [293/300], Loss: 0.3898\n",
            "Epoch [294/300], Loss: 0.6817\n",
            "Epoch [294/300], Loss: 0.7173\n",
            "Epoch [294/300], Loss: 0.6257\n",
            "Epoch [294/300], Loss: 0.7659\n",
            "Epoch [294/300], Loss: 0.7328\n",
            "Epoch [294/300], Loss: 0.3850\n",
            "Epoch [295/300], Loss: 0.6424\n",
            "Epoch [295/300], Loss: 0.6881\n",
            "Epoch [295/300], Loss: 0.6120\n",
            "Epoch [295/300], Loss: 0.7327\n",
            "Epoch [295/300], Loss: 0.7946\n",
            "Epoch [295/300], Loss: 1.3450\n",
            "Epoch [296/300], Loss: 0.8169\n",
            "Epoch [296/300], Loss: 0.7889\n",
            "Epoch [296/300], Loss: 0.6215\n",
            "Epoch [296/300], Loss: 0.6325\n",
            "Epoch [296/300], Loss: 0.6546\n",
            "Epoch [296/300], Loss: 0.7950\n",
            "Epoch [297/300], Loss: 0.7013\n",
            "Epoch [297/300], Loss: 0.6482\n",
            "Epoch [297/300], Loss: 0.7636\n",
            "Epoch [297/300], Loss: 0.7003\n",
            "Epoch [297/300], Loss: 0.7058\n",
            "Epoch [297/300], Loss: 0.4934\n",
            "Epoch [298/300], Loss: 0.5847\n",
            "Epoch [298/300], Loss: 0.7204\n",
            "Epoch [298/300], Loss: 0.7852\n",
            "Epoch [298/300], Loss: 0.7247\n",
            "Epoch [298/300], Loss: 0.7204\n",
            "Epoch [298/300], Loss: 0.2400\n",
            "Epoch [299/300], Loss: 0.7047\n",
            "Epoch [299/300], Loss: 0.6551\n",
            "Epoch [299/300], Loss: 0.6259\n",
            "Epoch [299/300], Loss: 0.8313\n",
            "Epoch [299/300], Loss: 0.6859\n",
            "Epoch [299/300], Loss: 0.4000\n",
            "Epoch [300/300], Loss: 0.6931\n",
            "Epoch [300/300], Loss: 0.7411\n",
            "Epoch [300/300], Loss: 0.6646\n",
            "Epoch [300/300], Loss: 0.6517\n",
            "Epoch [300/300], Loss: 0.7363\n",
            "Epoch [300/300], Loss: 1.2475\n"
          ]
        }
      ],
      "source": [
        "body_dataset = BodyFatDataset(data)\n",
        "batch_size=50\n",
        "dataset_loader = torch.utils.data.DataLoader(dataset=body_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "epochs=300\n",
        "input_size = 10\n",
        "output_size = 1\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for a, b in dataset_loader:\n",
        "    a, b = a.to(device), b.to(device)\n",
        "    model.train()\n",
        "    predictions = model(a)\n",
        "    loss = criterion(predictions, b)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2WipUpFJPQKk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}